---
title: "PopPsiSeq Dev1"
author: "Charlie Soeder"
date: "11/14/2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_chunk$set(root.dir = '/Users/csoeder/Research/PSIseq/PopPsiSeq/')
knitr::opts_knit$set(root.dir='/Users/csoeder/Research/PSIseq/PopPsiSeq/')
#knitr::opts_knit$set(root.dir='/proj/cdjones_lab/csoeder/PopPsiSeq/')
library("tidyverse")
library("knitr")


```

## 16 Nov 2018
```{r include=FALSE}
library("yaml")
getwd()
trammel <- read_yaml("config.yaml")
data_sets.df <- plyr::ldply(trammel$data_sets, data.frame)
data_sets.df$name <- as.factor(data_sets.df$name)
data_sets.df$paired<- as.factor(data_sets.df$paired)
data_sets.df$experimental<- as.factor(data_sets.df$experimental)
data_sets.df$species<- as.factor(data_sets.df$species)
data_sets.df$source<- as.factor(data_sets.df$source)
```

experimental data:

```{r echo=FALSE}
data_sets.df %>%  filter( !is.na(experimental)) %>%  select(c(name, paired, experimental, source)) %>%  arrange(experimental, desc(name)) %>% kable(caption="Sequenced Experimental Samples")
```

Population-wide sample count by species:

```{r echo=FALSE, results='asis'}
data_sets.df %>%  filter( !is.na(species)) %>% group_by(species) %>% summarise(sample_count=n()) %>% kable(caption="Number of Sequenced Samples per Species")
```


load & discuss FASTP summary


```{r echo=FALSE}

fastp_summary <- read_delim("meta/sequenced_reads.dat", "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
names(fastp_summary ) <- c("name","type","measure","value")
fastp_summary$name <- as.factor(fastp_summary$name)
fastp_summary$type <- as.factor(fastp_summary$type)
fastp_summary$measure <- as.factor(fastp_summary$measure)


#fastp_summary %>%  filter(type=="prefiltered" | type=="postfiltered") %>% filter(measure == "total_reads")


```

prefilt:

```{r echo=FALSE}

prefiltered_stats <- inner_join(fastp_summary %>%  filter(type=="prefiltered"), data_sets.df, by=c("name"="name"))

prefiltered_stats %>% filter(measure=='total_reads') %>%  summarise(minimum = min(value), average=mean(value) , maximum = max(value)) #filter(measure=="total_reads") %>% 


filtration_stats <- inner_join(fastp_summary %>%  filter(type=="prefiltered" | type == 'postfiltered'), data_sets.df, by=c("name"="name"))
filtration_stats$type <- factor(filtration_stats$type, levels=c("prefiltered", "postfiltered"))

pre_post_counts <- filtration_stats %>% filter(measure=='total_reads') %>%  group_by(type)  %>%  summarise(minimum = min(value), average=mean(value) , maximum = max(value)) 

#retention_percent <- filtration_stats %>% filter(measure=='total_reads') %>% select(c(name,type,value)) %>%  spread(type,value) %>% mutate(retention=100*postfiltered/prefiltered) %>%  summarise(type='percent retention', minimum = min(retention), average=mean(retention) , maximum = max(retention)) 

# patch 13 Dec 2018: have to filter by subgroup now that it's a field in the YAML? 
retention_percent <- filtration_stats %>% filter(measure=='total_reads') %>%  filter(subgroups=="all") %>% select(c(name,type,value)) %>%  spread(type,value) %>% mutate(retention=100*postfiltered/prefiltered) %>%  summarise(type='percent retention', minimum = min(retention), average=mean(retention) , maximum = max(retention)) 


rbind(pre_post_counts, retention_percent) %>% kable()
```

```{r echo=FALSE}
ggplot(filtration_stats %>% filter(measure == "total_reads")) + geom_line(aes(group=name, x=type,y=value)) +  geom_point(aes(x=type, y = value)) 
```

```{r echo=FALSE}

ggplot(filtration_stats %>% filter(measure == "q30_rate")) + geom_line(aes(group=name, x=type,y=value)) +  geom_point(aes(x=type, y = value)) 

```


```{r echo=FALSE}

dupe_stats <- inner_join(fastp_summary %>% filter(type=='duplication' & measure =='rate') %>%  mutate(percent=value*100) %>% select(c(name,percent)), data_sets.df, by=c("name"="name"))

```


## 19 Nov 2018

load and discuss bam summary

depth of coverage is effed???

```{r echo=FALSE}
vs_droSim1.bwa <- read_delim("meta/alignments.vs_droSim1.bwa.summary", "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
names(vs_droSim1.bwa) <- c("sample","measure","value")
vs_droSim1.bwa$aligner <- as.factor("bwa")
vs_droSim1.bwa$sample <- as.factor(vs_droSim1.bwa$sample)
vs_droSim1.bwa$measure <- as.factor(vs_droSim1.bwa$measure)


vs_droSim1.bwaUniq <- read_delim("meta/alignments.vs_droSim1.bwaUniq.summary", "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
names(vs_droSim1.bwaUniq) <- c("sample","measure","value")
vs_droSim1.bwaUniq$aligner <- as.factor("bwaUniq")
vs_droSim1.bwaUniq$sample <- as.factor(vs_droSim1.bwaUniq$sample)
vs_droSim1.bwaUniq$measure <- as.factor(vs_droSim1.bwaUniq$measure)
```

```{r echo=FALSE}

vs_droSim1.bwa %>%  filter(measure=='total_read_count' | measure == 'total_mapped_count')
vs_droSim1.bwaUniq %>%  filter( measure == 'total_mapped_count') %>% mutate(measure='filtered_mapped_count')




before_After.counts <- rbind(vs_droSim1.bwa %>%  filter(measure=='total_read_count' | measure == 'total_mapped_count'), vs_droSim1.bwaUniq %>%  filter( measure == 'total_mapped_count') %>% mutate(measure='filtered_mapped_count'))

before_After.counts$measure <- factor(before_After.counts$measure, levels = c('total_read_count','total_mapped_count','filtered_mapped_count'))

ggplot(before_After.counts) + geom_line(aes(group=sample, x=measure,y=value)) + geom_point(aes(x=measure, y=value, group=sample))


```

```{r echo=FALSE}
before_After.counts.aug <- before_After.counts %>% select(-c(aligner)) %>% spread(measure, value) %>%  mutate(mapping_retention=total_mapped_count/total_read_count, filter_retention = filtered_mapped_count/total_mapped_count)

before_After.counts.aug %>% gather(total_read_count:filtered_mapped_count, key="measure", value="value") %>%  group_by(measure) %>% summarise(minimum = min(value), average=mean(value), median = median(value), maximum = max(value))


```





```{r echo=FALSE}
before_After.cov <- inner_join( vs_droSim1.bwa %>%  filter(measure=='avg_depth' | measure == 'total_breadth') %>% select(-c(aligner)) %>% spread(measure, value), vs_droSim1.bwaUniq %>%  filter(measure=='avg_depth' | measure == 'total_breadth') %>% select(-c(aligner)) %>% spread(measure, value), by='sample', suffix=c(".before",".after") ) %>%  mutate(depth_retention = avg_depth.after/avg_depth.before, breadth_retention=total_breadth.after/total_breadth.before)
```

```{r echo=FALSE}

ggplot(before_After.counts) + geom_line(aes(group=sample, x=measure,y=value)) + geom_line(aes(group=sample, x=measure,y=value)) + geom_point(aes(x=measure, y=value, group=sample,color=sample)) + labs(title="Read Counts by Processing Step: Raw, Mapped, Filtered", x="", y="Number Reads" ) + scale_y_log10()

```


## 20 Nov 2018

Depth of coverage:

```{r echo=FALSE}

#before_After.cov %>% gather(avg_depth.before:breadth_retention, key=measure, value=value)

covstats.dpth <- before_After.cov %>% gather(avg_depth.before, key=measure, value=value) %>% summarise(step="pre-filtration depth",minimum = min(value), average=mean(value), median = median(value), maximum = max(value))

covstats.dpth <- rbind(covstats.dpth, before_After.cov %>% gather(avg_depth.after, key=measure, value=value)  %>% summarise(step="post-filtration depth",minimum = min(value), average=mean(value), median = median(value), maximum = max(value)))


covstats.dpth <- rbind(covstats.dpth, before_After.cov %>% gather(depth_retention, key=measure, value=value)  %>% summarise(step="depth retention",minimum = min(value), average=mean(value), median = median(value), maximum = max(value)))

covstats.dpth %>% kable(caption="Average Depth of Coverage for Raw and Filtered Alignments")


##report by subdivision:
before_After.cov.meta <- inner_join(before_After.cov, data_sets.df, by=c('sample'='name'))
before_After.cov.meta %>% group_by(species)  %>% gather(avg_depth.before, key=measure, value=value) %>% summarise(step="pre-filtration depth",minimum = min(value), average=mean(value), median = median(value), maximum = max(value)) 


```

```{r echo=FALSE}

before_After.cov.gathered.meta <- inner_join(before_After.cov %>%  gather(avg_depth.before:breadth_retention, key="measure", value="value") , data_sets.df, by=c("sample"="name") ) 

ggplot(before_After.cov.gathered.meta %>% filter(measure== "avg_depth.before" | measure== "avg_depth.after") %>% mutate(measure=factor(measure, levels=c("avg_depth.before" , "avg_depth.after" )))) + geom_line(aes(group=sample, x=measure,y=value, color=experimental)) + geom_point(aes(x=measure, y=value, group=sample)) + labs(title="Depth Of Coverage for Raw and Filtered Alignments", x="", y="Reads Per BP, Genome-Wide" )


```



```{r echo=FALSE}

covstats.brth <- before_After.cov %>% gather(total_breadth.before, key=measure, value=value) %>% summarise(step="pre-filtration breadth",minimum = 100*min(value), average=100*mean(value), median = 100*median(value), maximum = 100*max(value))

covstats.brth <- rbind(covstats.brth, before_After.cov %>% gather(total_breadth.after, key=measure, value=value)  %>% summarise(step="post-filtration breadth",minimum = 100*min(value), average=100*mean(value), median = 100*median(value), maximum = 100*max(value)))


covstats.brth <- rbind(covstats.brth, before_After.cov %>% gather(breadth_retention, key=measure, value=value)  %>% summarise(step="breadth retention",minimum = 100*min(value), average=100*mean(value), median = 100*median(value), maximum = 100*max(value)))

covstats.brth %>% kable(caption="Breadth of Coverage Statistics for Raw and Filtered Alignments", digits=1)

```




```{r echo=FALSE}


ggplot(before_After.cov.gathered.meta %>% filter(measure== "total_breadth.before" | measure== "total_breadth.after") %>% mutate(measure=factor(measure, levels=c("total_breadth.before" , "total_breadth.after" )))) + geom_line(aes(group=sample, x=measure,y=value, color=experimental)) + geom_point(aes(x=measure, y=value, group=sample)) + labs(title="Breadth Of Coverage for Raw and Filtered Alignments", x="", y="Percentage of Genome Mapped To" )
```


## 27 Nov 2018

better kable-tables with prettyNum() and sitools::f2si

https://stackoverflow.com/questions/3245862/format-numbers-to-significant-figures-nicely-in-r

sitools:
https://stackoverflow.com/questions/11340444/is-there-an-r-function-to-format-number-using-unit-prefix


```{r echo=FALSE}
library("sitools")

human_readable_croncher <- function(num_in) {
	dig <- 3
	num_out <- formatC(num_in, digits=dig, format='g') %>% as.numeric() %>% f2si()
	return(num_out)
}

```

```{r echo=FALSE}

rbind(pre_post_counts, retention_percent) %>%  mutate( minimum=human_readable_croncher(minimum), average=human_readable_croncher(average), maximum=human_readable_croncher(maximum)) %>% kable(caption="Read Counts by Sample")

```


```{r echo=FALSE}
covstats.brth  %>% mutate( minimum=human_readable_croncher(minimum), average=human_readable_croncher(average), maximum=human_readable_croncher(maximum)) %>% kable(caption="Breadth of Coverage Statistics for Raw and Filtered Alignments")
```

Also, need to add panels by reference genome. 

Also, some mention of reference genomes in the summary, with stats?


First, clean up the summarizers with a loading wrapper function
```{r echo=FALSE, include=FALSE}

bam_summary_loader <- function(filename, aligner="bwa", reference='dm6'){
	
	tmp.df <- read_delim(filename, "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
	names(tmp.df) <- c("sample","measure","value")
	
	tmp.df$sample <- as.factor(tmp.df$sample)
	tmp.df$measure <- as.factor(tmp.df$measure)
	tmp.df$aligner <- as.factor(aligner)
	tmp.df$reference <- as.factor(reference)
	
	return(tmp.df)
	
}

vs_droSim1.bwa <- bam_summary_loader(filename = "meta/alignments.vs_droSim1.bwa.summary",aligner="bwa", reference="droSim1")
vs_droSec1.bwa <- bam_summary_loader(filename = "meta/alignments.vs_droSec1.bwa.summary",aligner="bwa", reference="droSec1")
vs_droSim1.bwaUniq <- bam_summary_loader(filename = "meta/alignments.vs_droSim1.bwaUniq.summary",aligner="bwaUniq", reference="droSim1")
vs_droSec1.bwaUniq <- bam_summary_loader(filename = "meta/alignments.vs_droSec1.bwaUniq.summary",aligner="bwaUniq", reference="droSec1")

all_alignments <- rbind(vs_droSim1.bwa,vs_droSec1.bwa,vs_droSim1.bwaUniq,vs_droSec1.bwaUniq)


```


Previous stuff still works:

```{r echo=FALSE}

before_After.counts <- rbind(vs_droSim1.bwa %>%  filter(measure=='total_read_count' | measure == 'total_mapped_count'), vs_droSim1.bwaUniq %>%  filter( measure == 'total_mapped_count') %>% mutate(measure='filtered_mapped_count'))

before_After.counts$measure <- factor(before_After.counts$measure, levels = c('total_read_count','total_mapped_count','filtered_mapped_count'))

ggplot(before_After.counts) + geom_line(aes(group=sample, x=measure,y=value)) + geom_line(aes(group=sample, x=measure,y=value)) + geom_point(aes(x=measure, y=value, group=sample,color=sample)) + labs(title="Read Counts by Processing Step: Raw, Mapped, Filtered", x="", y="Number Reads" ) + scale_y_log10()

```

```{r echo=FALSE}
ggplot(all_alignments %>%  filter(measure=="avg_depth")) +geom_line(aes(x=aligner,y=value, group=sample), color="black")+ geom_point(aes(x=aligner,y=value, group=sample, color=sample)) + facet_grid(.~reference) + labs(title="Depth of Coverage")
```

```{r echo=FALSE}
ggplot(all_alignments %>%  filter(measure=="total_breadth"))+geom_line(aes(x=aligner,y=value, group=sample), color="black") + geom_point(aes(x=aligner,y=value, group=sample, color=sample)) + facet_grid(.~reference)+ labs(title="Breadth of Coverage")
```

## 28 Nov 2018

Retooling some diagrams and pipes



```{r echo=FALSE}

bam_sum_test <- all_alignments %>%  filter( (measure=='total_read_count' & aligner=="bwa") | measure == 'total_mapped_count' ) %>% mutate(measure=ifelse(aligner=="bwaUniq", "filtered_mapped_count", ifelse(measure=="total_read_count","total_read_count","total_mapped_count"))) 
bam_sum_test$measure <- factor(bam_sum_test$measure, levels = c('total_read_count','total_mapped_count','filtered_mapped_count'))

ggplot(bam_sum_test) + geom_line(aes(group=sample, x=measure,y=value)) + geom_point(aes(x=measure, y=value, group=sample,color=sample))+ facet_grid(.~reference) + labs(title="Read Counts by Processing Step: Raw, Mapped, Filtered", x="", y="Number Reads" ) + scale_y_log10()



bam_sum_test.spread <- bam_sum_test %>% select(-c(aligner)) %>%  spread(measure, value) %>%  mutate(mapping_retention=total_mapped_count/total_read_count, filter_retention = filtered_mapped_count/total_mapped_count)

bam_sum_test.spread %>% gather(total_read_count:filtered_mapped_count, key="measure", value="value") %>%  group_by(measure) %>% summarise(minimum = min(value), average=mean(value), median = median(value), maximum = max(value)) %>% mutate(minimum = human_readable_croncher(minimum), average=human_readable_croncher(average), median = human_readable_croncher(median), maximum = human_readable_croncher(maximum)) %>% kable(caption="Read Counts During Alignment & Filtration")
```

We can easily break down the table further with a second grouping:

```{r echo=FALSE}

bam_sum_test.spread %>% gather(total_read_count:filtered_mapped_count, key="measure", value="value") %>%  group_by(measure, reference) %>% summarise(minimum = min(value), average=mean(value), median = median(value), maximum = max(value)) %>% mutate(minimum = human_readable_croncher(minimum), average=human_readable_croncher(average), median = human_readable_croncher(median), maximum = human_readable_croncher(maximum)) %>% kable(caption="Read Counts During Alignment & Filtration")
```

using spread and gather to clean up this mess:
```{r echo=FALSE}

before_After.cov <- inner_join( vs_droSim1.bwa %>%  filter(measure=='avg_depth' | measure == 'total_breadth') %>% select(-c(aligner)) %>% spread(measure, value), vs_droSim1.bwaUniq %>%  filter(measure=='avg_depth' | measure == 'total_breadth') %>% select(-c(aligner)) %>% spread(measure, value), by='sample', suffix=c(".before",".after") ) %>%  mutate(depth_retention = avg_depth.after/avg_depth.before, breadth_retention=total_breadth.after/total_breadth.before)
```

```{r echo=FALSE}

depth.process <- all_alignments %>%  filter(measure=='avg_depth' ) %>% spread(aligner, value) %>%  mutate(depth_retention = 100*bwaUniq/bwa) %>% rename(before=bwa, after=bwaUniq)

covstats.dpth <- depth.process %>% summarise(step="pre-filtration depth",minimum = min(before), average=mean(before), median = median(before), maximum = max(before))

covstats.dpth <- rbind(covstats.dpth, depth.process %>% summarise(step="post-filtration depth",minimum = min(after), average=mean(after), median = median(after), maximum = max(after)))


covstats.dpth <- rbind(covstats.dpth, depth.process  %>% summarise(step="depth retention percent",minimum = min(depth_retention), average=mean(depth_retention), median = median(depth_retention), maximum = max(depth_retention)))


covstats.dpth %>% kable(caption="Depth of Coverage Statistics for Raw and Filtered Alignments", digits=1 )

```

```{r echo=FALSE}
ggplot(depth.process %>%  select(-c(depth_retention, measure)) %>%  gather(before:after, key=measure, value=value) %>% mutate(measure=factor(measure, levels=c("before","after"))) ) + geom_point(aes(group=sample, x=measure,y=value, color=sample)) + geom_line(aes(group=sample, x=measure,y=value)) + facet_grid(.~reference)

```

Again, just group_by() for a more detailed breakdown:

```{r echo=FALSE}
depth.process %>% group_by(reference)%>% summarise(step="pre-filtration depth",minimum = min(before), average=mean(before), median = median(before), maximum = max(before)) 
```


## 29 Nov 2018



```{r echo=FALSE}

breadth.process <- all_alignments %>%  filter(measure=='total_breadth' ) %>% spread(aligner, value) %>%  mutate(breadth_retention = 100*bwaUniq/bwa) %>% rename(before=bwa, after=bwaUniq)


covstats.brdth <- breadth.process %>% summarise(step="pre-filtration breadth",minimum = 100*min(before), average=100*mean(before), median = 100*median(before), maximum = 100*max(before))

covstats.brdth <- rbind(covstats.brdth, breadth.process %>% summarise(step="post-filtration breadth",minimum = 100*min(after), average=100*mean(after), median = 100*median(after), maximum = 100*max(after)))

covstats.brdth <- rbind(covstats.brdth, breadth.process  %>% summarise(step="breadth retention percent",minimum = min(breadth_retention), average=mean(breadth_retention), median = median(breadth_retention), maximum = max(breadth_retention)))

covstats.brdth %>% kable(caption="Breadth of Coverage Statistics for Raw and Filtered Alignments", digits=1 )

```


```{r echo=FALSE}
ggplot(breadth.process %>%  select(-c(breadth_retention, measure)) %>%  gather(before:after, key=measure, value=value) %>% mutate(measure=factor(measure, levels=c("before","after"))) ) + geom_point(aes(group=sample, x=measure,y=value, color=sample)) + geom_line(aes(group=sample, x=measure,y=value)) + facet_grid(.~reference)

```

do this to include script contents eg in the methods
```{r  engine='bash', comment='', tidy=TRUE, tidy.opts=list(width.cutoff=60)} 
cat scripts/bam_summarizer.py
```

yikes, looks like i might need to run a pep8 check LOL

VCFs are done building:

 cat all_samples.vs_droSim1.bwaUniq.vcf | head -n 1000 > all_samples.vs_droSim1.bwaUniq.vcf.subset



## 30 Nov 2018
```{r echo=FALSE}

reference_genomes.summaryStats <- read_delim("meta/reference_genomes.summary", "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)

names(reference_genomes.summaryStats) <- c("refGenome","measure","value")

reference_genomes.summaryStats %>% mutate( value=human_readable_croncher(value)) %>% spread(refGenome, value) %>% rename('Reference Genome:'=measure) %>% kable(caption="Size and Consolidation of Reference Genomes")

```


Shored up the command-line PDF generation to build the output in a designated path (ie, the PopPsiSeq head)

https://stackoverflow.com/questions/31463143/pass-parameters-from-command-line-into-r-markdown-document
https://github.com/yihui/knitr/issues/913


Starting basic stats on the VCFs....



total SNP count & rate:
```{r echo=FALSE}

all_samples.calledVariants.summaryStats <- read_delim("~/Research/PSIseq/PopPsiSeq/meta/all_samples.calledVariants.bwaUniq.summary", "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
names(all_samples.calledVariants.summaryStats) <-c("group", "refGenome","measure","value")

reference_genomes.summaryStats.sprud <- reference_genomes.summaryStats %>%  spread(measure,value) %>%  select(c(-number_contigs)) 

all_samples.calledVariants.snpCount <- inner_join(all_samples.calledVariants.summaryStats %>%  filter(measure=="total_snp_count") %>% spread(measure, value) , reference_genomes.summaryStats.sprud, by=c("refGenome"="refGenome"))

```

```{r echo=FALSE}

all_samples.calledVariants.snpCount %>%  mutate(snp_rate=1000*total_snp_count/number_bases, total_snp_count=human_readable_croncher(total_snp_count), number_bases=human_readable_croncher(number_bases) ) %>% select(-c(group)) %>% select(c(refGenome, number_bases, total_snp_count, snp_rate)) %>% rename(`reference genome` = refGenome,`Genome size (bp)`=number_bases, `total SNP count`=total_snp_count, `SNPs per kB`=snp_rate) %>% kable(caption="SNP count and per-KB SNP rate across all samples")


```

sample calls by site:

```{r echo=FALSE}
all_samples_vs_droSec1.lmiss <- read_delim("meta/VCFs/all_samples.vs_droSec1.bwaUniq.summary.lmiss", "\t", escape_double = FALSE, trim_ws = TRUE)
all_samples_vs_droSec1.lmiss$refgenome <- "droSec1"

all_samples_vs_droSim1.lmiss <- read_delim("meta/VCFs/all_samples.vs_droSim1.bwaUniq.summary.lmiss", "\t", escape_double = FALSE, trim_ws = TRUE)
all_samples_vs_droSim1.lmiss$refgenome <- "droSim1"


nsamps <- nrow(data_sets.df)


all_samples.lmiss <- rbind(all_samples_vs_droSim1.lmiss, all_samples_vs_droSec1.lmiss) %>% select(c(refgenome, N_MISS)) %>%  mutate(refgenome=as.factor(refgenome), N_PRES=nsamps-N_MISS)

```

```{r echo=FALSE}
ggplot(all_samples_vs_droSim1.lmiss %>% select(c(CHR, N_MISS)) %>%  mutate(CHR=as.factor(CHR), N_PRES=nsamps-N_MISS) ) + geom_freqpoly(aes(x=N_PRES, group=CHR, color=CHR), bins=nsamps)+ scale_x_continuous(name ="Number Samples",limits=c(1,nsamps), breaks =seq(1,nsamps,1)) + labs(title="Histogram of SNPs by Number of Samples Called At Site (droSim1)", y="Number of Sites")

```

```{r echo=FALSE}
ggplot(all_samples.lmiss) + geom_freqpoly(aes(x=N_PRES, group=refgenome, color=refgenome), bins=nsamps) + scale_x_continuous(name ="Number Samples",limits=c(1,nsamps), breaks =seq(1,nsamps,1)) + labs(title="Histogram of SNPs by Number of Samples Called At Site", y="Number of Sites")
```

uncalled sites by sample:

```{r echo=FALSE}
all_samples_vs_droSec1.imiss <- read_delim("meta/VCFs/all_samples.vs_droSec1.bwaUniq.summary.imiss", "\t", escape_double = FALSE, trim_ws = TRUE)
all_samples_vs_droSec1.imiss$refgenome <- "droSec1"

all_samples_vs_droSim1.imiss <- read_delim("meta/VCFs/all_samples.vs_droSim1.bwaUniq.summary.imiss", "\t", escape_double = FALSE, trim_ws = TRUE)
all_samples_vs_droSim1.imiss$refgenome <- "droSim1"

all_samples.imiss  <- rbind(all_samples_vs_droSec1.imiss, all_samples_vs_droSim1.imiss)  %>%  mutate(name=as.factor(INDV), refgenome=as.factor(refgenome), N_PRES=N_DATA-N_MISS) %>% select(c( name, N_MISS, N_PRES, F_MISS,refgenome))


```


```{r echo=FALSE}
ggplot(all_samples.imiss) + geom_freqpoly(aes(x=1-F_MISS, group=refgenome, color=refgenome), bins=7) + labs(title="Histogram of SNPs by Number of Samples Called At Site", y="Number of Individuals", x="Fraction of Jointly Called SNPs Callable per Individual") + scale_x_continuous(limits=c(0,1), breaks =seq(0,1,0.2))
```

```{r echo=FALSE}

all_samples.imiss.augmented <- inner_join(all_samples.imiss, breadth.process %>%  select(c(sample,reference,after)) %>% rename(breadth=after)%>% mutate(breadth = 100*breadth), by=c("name"="sample", "refgenome"="reference"))
all_samples.imiss.augmented <-inner_join(all_samples.imiss.augmented, depth.process %>%  select(c(sample,reference,after)) %>% rename(depth=after), by=c("name"="sample", "refgenome"="reference"))

all_samples.imiss.augmented <- all_samples.imiss.augmented %>%  gather(breadth:depth, key="measure", value="value")

```
https://stackoverflow.com/questions/15015356/how-to-do-selective-labeling-with-ggplot-geom-point 
```{r echo=FALSE}
ggplot(all_samples.imiss.augmented) + geom_point(aes(x= value, y=1-F_MISS, color=refgenome)) + facet_grid(.~measure, scales="free_x") + geom_text(data=subset(all_samples.imiss.augmented, 1-F_MISS < 0.75 & measure=="breadth"),aes(value,1-F_MISS,label=name))
```

## 3 Dec 2018


working on some of the analytics, using the vcftools standalone commands:

```{bash eval=FALSE, echo=TRUE}

vcf-subset variants/all_samples.vs_droSim1.bwaUniq.vcf -u -c SECH1,SECH2,SECH3 | head -n 200000 | vcftools --vcf - --recode --stdout > PopSech.vs_droSim1.bwaUniq.vcf 

vcftools  --vcf PopSech.vs_droSim1.bwaUniq.vcf --out potato --freq 


vcf-subset variants/all_samples.vs_droSim1.bwaUniq.vcf -u -c MD06m11d04y2010,MD73m11d04y2010,MD199m12d10y2010 | head -n 200000 | vcftools --vcf - --recode --stdout > PopSim.vs_droSim1.bwaUniq.vcf 

vcftools  --vcf PopSim.vs_droSim1.bwaUniq.vcf --out PopSim --freq 

vcf-subset variants/all_samples.vs_droSim1.bwaUniq.vcf -u -c SRR5860570,10A | head -n 200000 | vcftools --vcf - --recode --stdout > experimental.vs_droSim1.bwaUniq.vcf

vcftools  --vcf experimental.vs_droSim1.bwaUniq.vcf --out experimental --freq 
paste PopSech.frq PopSim.frq experimental.frq | awk '{if($3<3)print;}' | awk '{if($9<3)print;}' | awk '{if($15<3)print;}' |  cut -f 1,2,4,6,10,12,16,18 | grep -v nan | less


```

Add a group: PopSec,All tag or something in the config.yaml so that the -c string is callable

-u to keep uncalled sites

Maybe add filtering for sites (eg, AC > thresh, AF>thresh)

Filter down to biallelic sites? --min-alleles 2 --max-alleles 2

## 4 Dec 2018


```{bash eval=FALSE, echo=TRUE}
vcf-subset variants/all_samples.vs_droSim1.bwaUniq.vcf -u -c SECH1,SECH2,SECH3 | head -n 200000 | vcftools --min-alleles 2 --max-alleles 2  --max-missing-count 1  --vcf - --recode --stdout > PopSech.vs_droSim1.bwaUniq.vcf 

vcf-subset variants/all_samples.vs_droSim1.bwaUniq.vcf -u -c MD06m11d04y2010,MD73m11d04y2010,MD199m12d10y2010 | head -n 200000 | vcftools --min-alleles 2 --max-alleles 2  --max-missing-count 1  --vcf - --recode --stdout > PopSim.vs_droSim1.bwaUniq.vcf 

vcf-subset variants/all_samples.vs_droSim1.bwaUniq.vcf -u -c 10A | head -n 200000 | vcftools --min-alleles 2 --max-alleles 2  --max-missing-count 1  --vcf - --recode --stdout > experimental.vs_droSim1.bwaUniq.vcf 

vcftools  --vcf PopSech.vs_droSim1.bwaUniq.vcf --out PopSech --freq 
vcftools  --vcf PopSim.vs_droSim1.bwaUniq.vcf --out PopSim --freq 
vcftools  --vcf experimental.vs_droSim1.bwaUniq.vcf --out experimental --freq 


```
 --max-missing-count 1  sets the number of uncalled samples allowed per site (see also --max-missing [float] for fraction)

```{bash eval=FALSE, echo=TRUE}



bedtools intersect -wa -wb -a <(cat PopSech.frq | tail -n +2 | awk '{print $1,$2,$2+1,$4,$5,$6}' | tr " " "\t") -b <(cat PopSim.frq | tail -n +2 | awk '{print $1,$2,$2+1,$4,$5,$6}' | tr " " "\t") | bedtools intersect -wa -wb -a - -b <(cat experimental.frq | tail -n +2 | awk '{print $1,$2,$2+1,$4,$5,$6}' | tr " " "\t") | cut -f 1,2,4-6,10,12,16,18 | tr ":" "\t" | awk '{print $1,$2,$4,$6,$3,$7,$8,$10,$11,$13}' | tr " " "\t" | grep -w "chr2L" > dev/grouped_freaks.dat
 

```


```{r echo=FALSE}

grouped_freaks <- read_delim("dev/grouped_freaks.dat", "\t", escape_double = FALSE, col_names = FALSE, trim_ws = TRUE)
names(grouped_freaks) <- c("chrom", "pos", "ref", "alt", "sec_count", "sec_alt_af", "sim_count", "sim_alt_af","exp_count", "exp_alt_af")

grouped_freaks <- grouped_freaks %>% filter(!is.na(exp_alt_af))
grouped_freaks$sim_introg_deltaF <- (grouped_freaks$exp_alt_af - grouped_freaks$sim_alt_af) * sign(grouped_freaks$sim_alt_af-grouped_freaks$sec_alt_af)


grouped_freaks$sec_depletion_deltaF <- (grouped_freaks$exp_alt_af - grouped_freaks$sec_alt_af) * sign(grouped_freaks$sim_alt_af-grouped_freaks$sec_alt_af)


#ggplot(grouped_freaks %>% select(c(pos,sim_introg_deltaF,sec_depletion_deltaF)) %>%  gather(sim_introg_deltaF:sec_depletion_deltaF, key=measure, value=value) ) + geom_point(aes(x=pos,y=value,color=measure))

```

Plotting two values here: change in AF towards the AF in simulans (sim_introg_deltaF) and change away from the AF in sech (sec_depletion_deltaF)
(very chunky plot has been silenced)


## 11 Dec 2018

```{bash eval=FALSE, echo=TRUE}
grep "#" variants/all_samples.vs_droSim1.bwaUniq.vcf > all_samples.chr2L.vs_droSim1.bwaUniq.vcf
grep -v "#" variants/all_samples.vs_droSim1.bwaUniq.vcf | grep -w chr2L  >> all_samples.chr2L.vs_droSim1.bwaUniq.vcf


vcf-subset all_samples.chr2L.vs_droSim1.bwaUniq.vcf -u -c SECH1,SECH2,SECH3,SECH4 | vcftools --min-alleles 2 --max-alleles 2  --max-missing-count 1  --vcf - --recode --stdout > PopSech.chr2L.vs_droSim1.bwaUniq.vcf 

vcf-subset all_samples.chr2L.vs_droSim1.bwaUniq.vcf -u -c MD06m11d04y2010,MD73m11d04y2010,MD199m12d10y2010,NS79m03d07y2011  | vcftools --min-alleles 2 --max-alleles 2  --max-missing-count 1  --vcf - --recode --stdout > PopSim.chr2L.vs_droSim1.bwaUniq.vcf 

vcf-subset all_samples.chr2L.vs_droSim1.bwaUniq.vcf -u -c 10A,10B,17A,17B,SRR303333 | vcftools --min-alleles 2 --max-alleles 2  --max-missing-count 1  --vcf - --recode --stdout > selection.chr2L.vs_droSim1.bwaUniq.vcf 
```


(this could ultimately be implemented thus:)

```{python eval=FALSE, echo=TRUE}
sampname_by_group = {}
for s in sample_by_name.keys():
	subgroup_str = sample_by_name[s]['subgroups']
	subgroup_lst = subgroup_str.split(",")
	for g in subgroup_lst:
		if g in sampname_by_group.keys:
			sampname_by_group[g].append(s)
		else:
			sampname_by_group[g] = [s]

#
#	......
#

rule subset_VCF_to_subgroup:
	input:
		vcf_in = "variants/{prefix}.vs_{ref_genome}.{aligner}.vcf"
	output:
		vcf_out = "variants/{prefix}.subset_{subgroup}.vs_{ref_genome}.{aligner}.vcf"
	run:
		member_list = "%s,"*len(sampname_by_group[wildcards.subgroup]) % tuple(sampname_by_group[wildcards.subgroup])
		shell("vcf-subset {input.vcf_in} -u -c {member_list} | vcftools --min-alleles 2 --max-alleles 2  --max-missing-count 1  --vcf - --recode --stdout > {output.vcf_out}")

```
uh.... wait, gotta see how YAML handles CSV lists.


```{bash eval=FALSE, echo=TRUE}

vcftools  --vcf PopSech.chr2L.vs_droSim1.bwaUniq.vcf --out PopSech.chr2L.vs_droSim1.bwaUniq --freq 
vcftools  --vcf PopSim.chr2L.vs_droSim1.bwaUniq.vcf --out PopSim.chr2L.vs_droSim1.bwaUniq --freq 
vcftools  --vcf selection.chr2L.vs_droSim1.bwaUniq.vcf --out selection.chr2L.vs_droSim1.bwaUniq --freq 


bedtools intersect -wa -wb -a <(cat PopSech.chr2L.vs_droSim1.bwaUniq.frq | tail -n +2 | awk '{print $1,$2,$2+1,$4,$5,$6}' | tr " " "\t") -b <(cat PopSim.chr2L.vs_droSim1.bwaUniq.frq | tail -n +2 | awk '{print $1,$2,$2+1,$4,$5,$6}' | tr " " "\t") | bedtools intersect -wa -wb -a - -b <(cat selection.chr2L.vs_droSim1.bwaUniq.frq | tail -n +2 | awk '{print $1,$2,$2+1,$4,$5,$6}' | tr " " "\t") | cut -f 1,2,4-6,10,12,16,18 | tr ":" "\t" | awk '{print $1,$2,$2+1,"0","0","+",$4,$6,$3,$7,$8,$10,$11,$13}' | tr " " "\t" > dev/grouped_freaks2.bed


```



```{r echo=FALSE}

library("rtracklayer")
#source("http://bioconductor.org/biocLite.R")
#biocLite("ggbio")
library("ggbio")

chr2L.freqCompare.bg <- import.bedGraph("dev/grouped_freaks2.bed", genome="droSim1")
names(mcols(chr2L.freqCompare.bg)) <-  c("score", "name", "blup", "ref", "alt", "sec_count", "sec_alt_af", "sim_count", "sim_alt_af","exp_count", "exp_alt_af")

chr2L.freqCompare.bg$sim_introg_deltaF <- (chr2L.freqCompare.bg$exp_alt_af - chr2L.freqCompare.bg$sim_alt_af) * sign(chr2L.freqCompare.bg$sim_alt_af-chr2L.freqCompare.bg$sec_alt_af)


chr2L.freqCompare.bg$sec_depletion_deltaF <- (chr2L.freqCompare.bg$exp_alt_af - chr2L.freqCompare.bg$sec_alt_af) * sign(chr2L.freqCompare.bg$sim_alt_af-chr2L.freqCompare.bg$sec_alt_af)


#tests to confirm this metric does what I think it does
#chr2L.freqCompare.bg %>%  mcols() %>% as.tibble() %>% filter(sim_introg_deltaF < 0) %>%  View()

autoplot(chr2L.freqCompare.bg, aes(y=sim_introg_deltaF), geom='point') + theme_clear()

```



site count, binned by allele number at site:

```{bash eval=TRUE, echo=FALSE}
cat meta/VCFs/all_samples.vs_droSim1.bwaUniq.summary.frq | tail -n +2 | cut -f 3 | sort | uniq -c | awk '{print $2,$1}' | tr " " "\t"
```

Might multiallelic sites be of interest?


## 14 Dec 2018


Try windowing? Can always copy-paste the windowmaker and windowcounter rules from the PsiSeq2 snakefile. The question would be whether to do this within the R script or as part of the Snakemake workflow? 

note that there are some extra columns in this particular GRange...

```{bash eval=TRUE, echo=FALSE}
bedtools  makewindows -g /proj/cdjones_lab/Genomics_Data_Commons/genomes/drosophila_simulans/droSim1.fa.fai -w 100000 > utils/droSim1_w100000_s100000.windows.bed


```


Writing a GRange object to a BED file...
https://www.biostars.org/p/89341/

```{r echo=FALSE}
chr2L.freqCompare.df <- data.frame(seqnames=seqnames(chr2L.freqCompare.bg),
  starts=start(chr2L.freqCompare.bg)-1,
  ends=end(chr2L.freqCompare.bg),
  names=c(rep(".", length(chr2L.freqCompare.bg))),
  scores=c(rep(".", length(chr2L.freqCompare.bg))),
  strands=strand(chr2L.freqCompare.bg)  )

chr2L.freqCompare.df <- cbind(chr2L.freqCompare.df, mcols(chr2L.freqCompare.bg))


write.table(chr2L.freqCompare.df, file="chr2L.freqCompare.bed", quote=F, sep="\t", row.names=F, col.names=F)

```


## 17 December 2018

Idea: for each bin, calculate a population-wide heatmap/phylogeny base on SNP data. Animate via gganimate or gif?

install.packages("devtools")
devtools::install_github("dgrtwo/gganimate")
install.packages("gifski")

https://www.ggplot2-exts.org/gganimate.html
https://www.rdocumentation.org/packages/gganimate/versions/0.1.1
(check the cumulative = True setting.... use this for chromosomal location progress bar?? )
https://stackoverflow.com/questions/51440496/using-gganimate-to-export-gif




```{bash eval=FALSE, echo=FALSE}

bedtools map -c 18,19,19 -o sum,sum,count -null NA -a utils/droSim1_w100000_s100000.windows.bed -b chr2L.freqCompare.bed  > {output.window_counts}
```


uh.... why does bedtools not find overlaps here?

```{bash eval=TRUE, echo=FALSE}
cat chr2L.freqCompare.bed | cut -f 1,2,3,6,18,19 | nl | tr -d " " | awk '{print $2,$3,$4,$1,"0",".",$6,$7}' | tr " " "\t" > chr2L.freqCompare.clean.bed 
```

uhhhhh

```{bash eval=TRUE, echo=FALSE}
cat utils/droSim1_w100000_s100000.windows.bed | grep -w "chr2L" > dev/droSim1_w100000_s100000.windows.chr2L.bed  

```

Ok, this gives results. Whatever. May be some sort of sorting issue? May go away totally using HelloRanges or a non-subsetted frq file? whatever, moving on for now...

```{bash eval=TRUE, echo=FALSE}
bedtools map -c 7,8,8 -o sum,sum,count -null NA -a dev/droSim1_w100000_s100000.windows.chr2L.bed -b chr2L.freqCompare.clean.bed > dev/chr2L.freqCompare.windowed.bed
```



```{r echo=FALSE}
chr2L.freqCompare.windowed.bg <- import.bedGraph("dev/chr2L.freqCompare.windowed.bed", genome="droSim1")
names(mcols(chr2L.freqCompare.windowed.bg)) <-  c("sum_sim_introg_deltaF", "sum_sec_depl_deltaF", "num_snp")

chr2L.freqCompare.windowed.bg$avg_sim_introg <- chr2L.freqCompare.windowed.bg$sum_sim_introg_deltaF/chr2L.freqCompare.windowed.bg$num_snp
chr2L.freqCompare.windowed.bg$avg_sec_depl <- chr2L.freqCompare.windowed.bg$sum_sec_depl_deltaF/chr2L.freqCompare.windowed.bg$num_snp


chr2L.freqCompare.windowed.snpCount.tk <- autoplot(chr2L.freqCompare.windowed.bg, aes(y=num_snp), geom='line') + theme_clear()
chr2L.freqCompare.windowed.simIntrog.tk <- autoplot(chr2L.freqCompare.windowed.bg, aes(y=avg_sim_introg), geom='line') + theme_clear()
chr2L.freqCompare.windowed.secDeplet.tk <- autoplot(chr2L.freqCompare.windowed.bg, aes(y=avg_sec_depl), geom='line') + theme_clear()

tks <- tracks( number_SNPs = chr2L.freqCompare.windowed.snpCount.tk, simulans_similarity = chr2L.freqCompare.windowed.simIntrog.tk, sechellia_dissimilarity = chr2L.freqCompare.windowed.secDeplet.tk )#,heights = c(2, 3, 3, 1, 4)) + theme_tracks_sunset()

tks
```

http://www.sthda.com/english/wiki/ggbio-visualize-genomic-data

Well that's nice and crisp, albeit with no comparison to control....

Cleaning up 

```{bash eval=FALSE, echo=FALSE}
cat all_samples.chr2L.vs_droSim1.bwaUniq.vcf | grep -v "#" | sed -e 's/0\/0:\S*\(\s\|$\)/0\t/g'  | sed -e 's/0\/1:\S*\(\s\|$\)/1\t/g' | sed -e 's/1\/0:\S*\(\s\|$\)/1\t/g' | sed -e 's/1\/1:\S*\(\s\|$\)/2\t/g' | sed -e 's/\.:\S*\(\s\|$\)/NA\t/g' 

```


calculating a windowed distance matrix lends itself to the snakemake recursive workflow. (Look back at the human developmental RNA workflow for hints on building an n*n triangular matrix in Snakemake )







biocLite("HelloRanges")



