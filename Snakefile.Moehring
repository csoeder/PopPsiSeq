configfile: 'config.yaml'

from Bio import SeqIO
from subprocess import CalledProcessError
# module load python/3.9.6 sratoolkit samtools freebayes vcftools bwa bedtools r/4.2.2 rstudio bedops
#PATH=$PATH:/nas/longleaf/home/csoeder/modules/vcflib/bin:/nas/longleaf/home/csoeder/modules/parallel/bin


sample_by_name = {c['name'] : c for c in config['data_sets']}
ref_genome_by_name = { g['name'] : g for g in config['reference_genomes']}
chain_dict_by_destination = config['lift_genomes']
annotation_by_name = { a['name'] : a for a in config['annotations']}

sampname_by_group = {}
sampname_by_sra = {}
#print(sample_by_name)

for s in sample_by_name.keys():
	subgroup_lst = sample_by_name[s]['subgroups']
	for g in subgroup_lst:
		if g in sampname_by_group.keys():
			sampname_by_group[g].append(s)
		else:
			sampname_by_group[g] = [s]

	try:
		sampname_by_sra[sample_by_name[s]['SRA']] = s
	except KeyError:
		pass


def return_filename_by_sampname(sampname):
	filenames = []
	if sample_by_name[sampname]['paired']:
		filenames.append(sample_by_name[sampname]['readsfile1'])
		filenames.append(sample_by_name[sampname]['readsfile2'])
	else:
		filenames.append(sample_by_name[sampname]['readsfile'])
	return filenames

def return_file_relpath_by_sampname(wildcards):
	sampname = wildcards.samplename
	pathprefix = sample_by_name[sampname]["path"]
	filesin = return_filename_by_sampname(sampname)
	pathsout = ["".join([pathprefix, fq]) for fq in filesin]
	return pathsout




rule all:
	input: 
		pdf_out="results/Moehring_PopPsiSeq.pdf",
	params:
		runmem_gb=1,
		runtime="0:01:00",
		cores=1,
	run:
		shell(""" mkdir -p results/figures/; touch results/figures/null.png; for fig in results/figures/*png; do mv $fig $(echo $fig| rev | cut -f 2- -d . | rev ).$(date +%d_%b_%Y).png; done;  rm results/figures/null.*.png; """)
		shell(""" mkdir -p results/figures/supp/ ; touch results/figures/supp/null.png; for fig in results/figures/supp/*png; do mv $fig $(echo $fig| rev | cut -f 2- -d . | rev ).$(date +%d_%b_%Y).png; done; rm results/figures/supp/null.*.png; """)

		shell(""" mkdir -p results/tables/ ; touch results/tables/null.tmp ; for phial in $(ls -p results/tables/ | grep -v /); do pre=$(echo $phial | rev | cut -f 2- -d . | rev ); suff=$(echo $phial | rev | cut -f 1 -d . | rev ); mv results/tables/$phial results/tables/$pre.$(date +%d_%b_%Y).$suff; done ; rm results/tables/null.*.tmp; """)
		shell(""" mkdir -p results/tables/supp/ ; touch results/tables/supp/null.tmp ; for phial in $(ls -p results/tables/supp/ | grep -v /); do pre=$(echo $phial | rev | cut -f 2- -d . | rev ); suff=$(echo $phial | rev | cut -f 1 -d . | rev ); mv results/tables/supp/$phial results/tables/supp/$pre.$(date +%d_%b_%Y).$suff; done ; rm results/tables/supp/null.*.tmp; """)

		shell(""" mv results/Moehring_PopPsiSeq.pdf results/Moehring_PopPsiSeq.$(date +%d_%b_%Y).pdf """)
		shell(""" tar cf Moehring_PopPsiSeq.$(date +%d_%b_%Y).tar results/ """)











############################################################################  
#######		background data, eg reference genomes 	####
############################################################################  


rule reference_genome_reporter:
	input:
		fai_in = lambda wildcards: ref_genome_by_name[wildcards.ref_gen]['fai'],
	output:
		report_out = "data/summaries/reference_genomes/{ref_gen}.fai.report"
	params:
		runmem_gb=1,
		runtime="5:00",
		cores=1,
	shell:
		"""
		mkdir -p data/summaries/reference_genomes/
		cat {input.fai_in} | awk '{{sum+=$2}} END {{ print "number_contigs\t",NR; print "number_bases\t",sum}}' | sed -e 's/^/{wildcards.ref_gen}\t/g' > {output.report_out};
		"""

rule demand_reference_genome_summary:
	input:
		refgen_reports = lambda wildcards: expand("data/summaries/reference_genomes/{ref_gen}.fai.report", ref_gen=ref_genome_by_name.keys())
	output:
		refgen_summary = "data/summaries/reference_genomes/reference_genomes.summary"
	params:
		runmem_gb=1,
		runtime="5:00",
		cores=1,
	shell:
		"cat {input.refgen_reports} > {output.refgen_summary}"




rule annotation_reporter:
	input:
		annot = lambda wildcards: annotation_by_name[wildcards.annot_name]["gtf_path"]
	output:
		report_out = "data/summaries/reference_annotations/{annot_name}.stats"
	params:
		runmem_gb=1,
		runtime="5:00",
		cores=1,
	run:
		shell(""" mkdir -p data/summaries/reference_annotations/ """)
		shell(""" rm -f {output.report_out} """)
		shell(""" cat {input.annot} | awk '{{if($3=="gene")print;}}' | gtf2bed | cut -f 1-6 | cut -f 1  | sort | uniq -c | tr -s " " | tr " " "\t" | awk '{{print"count\t"$2"\t"$1}}' >> {output.report_out} """)
		shell(""" cat {input.annot} | awk '{{if($3=="gene")print;}}' | gtf2bed | cut -f 1-6 | wc -l | awk '{{print"count\ttotal\t"$0}}' >> {output.report_out} """)
		shell(""" cat {input.annot} | awk '{{if($3=="gene")print;}}' | gtf2bed | cut -f 1-6 | awk '{{print$3-$2;}}' | awk '{{sum+=$1; sumsq+=$1*$1}} END {{ print "size\ttotal\t",sum; print "size\tavg\t",sum/NR; print "size\tstd\t",sqrt(sumsq/NR - (sum/NR)**2)}}'  >> {output.report_out} """)


rule summon_annotation_summaries:
	input:
		refgen_reports = lambda wildcards: expand("data/summaries/reference_annotations/{ref_ann}.stats", ref_ann= [a["name"] for a in config['annotations']  ] ) # annotation_by_name.keys())
	output:
		refann_summary = "data/summaries/reference_annotations/reference_annotations.summary"
	params:
		runmem_gb=1,
		runtime="5:00",
		cores=1,
	run:
		print([a["name"] for a in config['annotations'] ])
		shell(""" rm -f {output.refann_summary} """)
		for anne in [a["name"] for a in config['annotations']  ]:
			shell(""" cat data/summaries/reference_annotations/{anne}.stats | awk '{{print"{anne}\t"$0}}' >> {output.refann_summary}""")


############################################################################  
#######		Read files: summon them, process them 	####
############################################################################  

#print(sampname_by_sra)
rule summon_reads_SRA_pe:
	output:
		reads1='data/external/sequence/paired_end/{prefix}/{prefix}_1.fastq',
		reads2='data/external/sequence/paired_end/{prefix}/{prefix}_2.fastq',
	params:
		runmem_gb=8,
		runtime="3:00:00",
		cores=1,
	run:
		try:
			sra = sampname_by_sra[wildcards.prefix]#["SRA"]
			shell(""" mkdir -p data/external/sequence/paired_end/{wildcards.prefix}/ """)
			shell("""
				fasterq-dump  --split-3 --outdir data/external/sequence/paired_end/{wildcards.prefix}/ {wildcards.prefix}
			""")
		except KeyError:
			raise KeyError("Sorry buddy, you can only download SRAs that are associated with a sample in the config file! " )

rule summon_reads_SRA_se:
	output:
		reads='data/external/sequence/single_end/{prefix}/{prefix}.fastq',
	params:
		runmem_gb=8,
		runtime="3:00:00",
		cores=1,
	run:

		try:
			sra = sampname_by_sra[wildcards.prefix]#["SRA"]
			shell(""" mkdir -p data/external/sequence/single_end/{wildcards.prefix}/ """)
			# shell("""
				# fasterq-dump  --split-3 --outdir data/external/sequence/single_end/{wildcards.prefix}/ {sra}
			# """)
			shell("""
				fasterq-dump  --split-3 --outdir data/external/sequence/single_end/{wildcards.prefix}/ {wildcards.prefix}
			""")

		except KeyError:
			raise KeyError("Sorry buddy, you can only download SRAs that are associated with a sample in the config file! " )



# data/ultimate/freq_shift/all.melvinCntrl_with_melvinSim_and_melvinSech.vs_dm6.bwaUniq.windowed_w100000_s100000.frqShift.bed data/ultimate/freq_shift/all.melvinSelect_with_melvinSim_and_melvinSech.vs_dm6.bwaUniq.windowed_w100000_s100000.frqShift.bed data/ultimate/freq_shift/all.melvinCntrl_with_melvinSim_and_melvinSech.vs_droSim1.bwaUniq.windowed_w100000_s100000.frqShift.bed data/ultimate/freq_shift/all.melvinSelect_with_melvinSim_and_melvinSech.vs_droSim1.bwaUniq.windowed_w100000_s100000.frqShift.bed data/ultimate/freq_shift/all.melvinCntrl_with_melvinSim_and_melvinSech.vs_droSec1.bwaUniq.windowed_w100000_s100000.frqShift.bed data/ultimate/freq_shift/all.melvinSelect_with_melvinSim_and_melvinSech.vs_droSec1.bwaUniq.windowed_w100000_s100000.frqShift.bed
# data/ultimate/freq_shift/all.Earley2011Selection_with_labSim_and_labSech.vs_dm6.bwaUniq.windowed_w100000_s100000.frqShift.bed data/ultimate/freq_shift/all.Earley2011Selection_with_labSim_and_wildSech.vs_dm6.bwaUniq.windowed_w100000_s100000.frqShift.bed 


def return_file_relpath_by_sampname(sampname):


	if sample_by_name[sampname]["source"] in ["NCBI"]:
		subfolder = sample_by_name[sampname]["SRA"]
		path = "data/external/sequence/"

	else:
		subfolder = sampname
		path = "data/raw/sequence/"

	if sample_by_name[sampname]["paired"] :
		path = "%spaired_end/%s/" % (path, subfolder)

	else:
		path = "%ssingle_end/%s/" % (path,subfolder)

	filesin = return_filename_by_sampname(sampname)
	pathsout = ["".join([path, fq]) for fq in filesin]

	return pathsout

def return_file_relpath_by_sampname(sampname):


	pith = sample_by_name[sampname]["path"]

	filesin = return_filename_by_sampname(sampname)
	pathsout = ["".join([pith, fq]) for fq in filesin]

	return pathsout


rule fastp_clean_sample_se:
	input:
		fileIn = lambda wildcards: return_file_relpath_by_sampname(wildcards.samplename)
	output:
		fileOut = ["data/intermediate/sequence/{samplename}/{samplename}.clean.R0.fastq"],
#		fileOut = ["{pathprefix}/{samplename}.clean.R0.fastq"],
		jason = "data/intermediate/sequence/{samplename}/{samplename}.False.json"
	params:
		runmem_gb=8,
		runtime="3:00:00",
		cores=1,
		#--trim_front1 and -t, --trim_tail1
		#--trim_front2 and -T, --trim_tail2. 
		common_params = "--json data/intermediate/sequence/{samplename}/{samplename}.False.json",# --html meta/FASTP/{samplename}.html", 
		se_params = "",
	message:
		"FASTP QA/QC on single-ended reads ({wildcards.samplename}) in progress.... "
	run:
		shell(""" mkdir -p data/intermediate/sequence/{wildcards.samplename}/ """)
		shell(""" /nas/longleaf/home/csoeder/modules/fastp/fastp {params.common_params} {params.se_params} --in1 {input.fileIn[0]} --out1 {output.fileOut[0]} """)
		


rule fastp_clean_sample_pe:
	input:
		fileIn = lambda wildcards: return_file_relpath_by_sampname(wildcards.samplename)
	output:
		fileOut = ["data/intermediate/sequence/{samplename}/{samplename}.clean.R1.fastq","data/intermediate/sequence/{samplename}/{samplename}.clean.R2.fastq"],
		jason = "data/intermediate/sequence/{samplename}/{samplename}.True.json"
	params:
		runmem_gb=8,
		runtime="3:00:00",
		cores=1,
		#--trim_front1 and -t, --trim_tail1
		#--trim_front2 and -T, --trim_tail2. 
		common_params = "--json data/intermediate/sequence/{samplename}/{samplename}.True.json",# --html meta/FASTP/{samplename}.html", 
		pe_params = "--detect_adapter_for_pe --correction",
	message:
		"FASTP QA/QC on paired-ended reads ({wildcards.samplename}) in progress.... "
	run:
		shell(""" mkdir -p data/intermediate/sequence/{wildcards.samplename}/ """)
		shell(""" /nas/longleaf/home/csoeder/modules/fastp/fastp {params.common_params} {params.pe_params} --in1 {input.fileIn[0]} --out1 {output.fileOut[0]} --in2 {input.fileIn[1]} --out2 {output.fileOut[1]} """)


rule FASTP_summarizer:
	input: 
		jason = lambda wildcards: expand("data/intermediate/sequence/{samp}/{samp}.{pairt}.json", samp = wildcards.samplename, pairt = sample_by_name[wildcards.samplename]['paired'])
#		jason = lambda wildcards: expand("{path}{samp}.{pairt}.json", path=sample_by_name[wildcards.samplename]['path'], samp = wildcards.samplename, pairt = sample_by_name[wildcards.samplename]['paired'])
	output:
		jason_pruned = "data/summaries/intermediate/FASTP/{samplename}/{samplename}.json.pruned"
	params:
		runmem_gb=1,
		runtime="5:00",
		cores=1,
	message:
		"Summarizing reads for sample ({wildcards.samplename}) .... "	
	shell:
		"""
		mkdir -p data/summaries/intermediate/FASTP/{wildcards.samplename}/
		cp {input.jason} data/summaries/intermediate/FASTP/{wildcards.samplename}/{wildcards.samplename}.json
		python3 scripts/fastp_reporter.py {input.jason} {output.jason_pruned} -t {wildcards.samplename}
		"""

rule demand_FASTQ_analytics:	#forces a FASTP clean
	input:
		jasons_in = lambda wildcards: expand("data/summaries/intermediate/FASTP/{samplename}/{samplename}.json.pruned", samplename = sampname_by_group[wildcards.group])
	output:
		summary = "data/summaries/intermediate/FASTP/{group}.sequenced_reads.dat"
	params:
		runmem_gb=1,
		runtime="1:00",
		cores=1,
	message:
		"Collecting read summaries for all samples ...."
	shell:
		"cat {input.jasons_in} > {output.summary}"



############################################################################  
#######		Map reads to reference genomes 	####
############################################################################  


rule bwa_align:
	input:
#		reads_in = lambda wildcards: expand("data/intermediate/FASTQs/{source}/{sample}/{sample}.clean.R{arr}.fastq", source=sample_by_name[wildcards.sample]['source'], sample=wildcards.sample, arr=[ [1,2] if sample_by_name[wildcards.sample]['paired'] else [0] ][0]),
		reads_in = lambda wildcards: expand("data/intermediate/sequence/{sample}/{sample}.clean.R{arr}.fastq", sample=wildcards.sample, arr=[ [1,2] if sample_by_name[wildcards.sample]['paired'] else [0] ][0]),
		ref_genome_file = lambda wildcards: ref_genome_by_name[wildcards.ref_genome]['path'],
	output:
		bam_out = "data/intermediate/mapped_reads/bwa/{sample}.vs_{ref_genome}.bwa.sort.bam",
	params:
		runmem_gb=96,
		runtime="64:00:00",
		cores=8,
	message:
		"aligning reads from {wildcards.sample} to reference_genome {wildcards.ref_genome} .... "
	run:
		shell("bwa aln {input.ref_genome_file} {input.reads_in[0]} > {input.reads_in[0]}.{wildcards.ref_genome}.sai ")
		if sample_by_name[wildcards.sample]['paired']:
			shell("bwa aln {input.ref_genome_file} {input.reads_in[1]} > {input.reads_in[1]}.{wildcards.ref_genome}.sai ")
			shell("bwa sampe {input.ref_genome_file} {input.reads_in[0]}.{wildcards.ref_genome}.sai {input.reads_in[1]}.{wildcards.ref_genome}.sai {input.reads_in[0]}  {input.reads_in[1]} | samtools view -Shb | samtools addreplacerg -r ID:{wildcards.sample} -r SM:{wildcards.sample} - | samtools sort -o {output.bam_out} - ")
		else:
			shell("bwa samse {input.ref_genome_file} {input.reads_in[0]}.{wildcards.ref_genome}.sai {input.reads_in[0]} | samtools view -Shb | samtools addreplacerg -r ID:{wildcards.sample} -r SM:{wildcards.sample} - | samtools sort -o {output.bam_out} - ")
		shell("samtools index {output.bam_out}")


#	request stats/idxstats/flagstats?  

rule bwa_uniq:
	input:
		bam_in = "data/intermediate/mapped_reads/bwa/{sample}.vs_{ref_genome}.bwa.sort.bam"
	output:
		bam_out = "data/intermediate/mapped_reads/bwaUniq/{sample}.vs_{ref_genome}.bwaUniq.sort.bam"
	params:
		quality="-q 20 -F 0x0100 -F 0x0200 -F 0x0300 -F 0x04",
		uniqueness="XT:A:U.*X0:i:1.*X1:i:0",
		runmem_gb=16,
		runtime="18:00:00",
		cores=4,
	message:
		"filtering alignment of {wildcards.sample} to {wildcards.ref_genome} for quality and mapping uniqueness.... "	
	run:
		ref_genome_file=ref_genome_by_name[wildcards.ref_genome]['path']
		#original; no dedupe
		#"samtools view {params.quality} {input.bam_in} | grep -E {params.uniqueness} | samtools view -bS -T {ref_genome} - | samtools sort -o {output.bam_out} - "
		shell("samtools view {params.quality} {input.bam_in} | grep -E {params.uniqueness} | samtools view -bS -T {ref_genome_file} - | samtools addreplacerg -r ID:{wildcards.sample} -r SM:{wildcards.sample} - | samtools sort -n - | samtools fixmate -m - - | samtools sort - | samtools markdup -r - {output.bam_out}")
		shell("samtools index {output.bam_out}")



rule bam_reporter:
	input:
		bam_in = "data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.sort.bam"
	output:
		report_out = "data/summaries/intermediate/BAMs/{aligner}/{sample}.vs_{ref_genome}.{aligner}.summary",
		dpth_by_chrom = "data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.sort.bam.dpth_by_chrom"
	params:
		runmem_gb=8,
		runtime="4:00:00",
		cores=1,
	message:
		"Collecting metadata for the {wildcards.aligner} alignment of {wildcards.sample} to {wildcards.ref_genome}.... "
	run:
		shell(""" mkdir -p data/summaries/intermediate/BAMs/{wildcards.aligner}/ """)
		ref_genome_idx=ref_genome_by_name[wildcards.ref_genome]['fai']
		shell("samtools idxstats {input.bam_in} > {input.bam_in}.idxstats")
		shell("samtools flagstat {input.bam_in} > {input.bam_in}.flagstat")
		shell("bedtools genomecov -max 1 -ibam {input.bam_in} -g {ref_genome_idx} > {input.bam_in}.genomcov")
		#change the -max flag as needed to set 
		shell("""samtools depth -a {input.bam_in}  > {input.bam_in}.dpth.tmp """)
		shell(""" cat {input.bam_in}.dpth.tmp | awk '{{sum+=$3; sumsq+=$3*$3}} END {{ print "average_depth\t",sum/NR; print "std_depth\t",sqrt(sumsq/NR - (sum/NR)**2)}}' > {input.bam_in}.dpthStats""")

		shell(""" 
		rm -rf {input.bam_in}.dpth_by_chrom;
		for chrom in $(cat {ref_genome_idx} | cut -f 1); do 
		cat {input.bam_in}.dpth.tmp | grep -w "$chrom" | awk '{{sum+=$3; sumsq+=$3*$3}} END {{ print "average_depth\t",sum/NR; print "std_depth\t",sqrt(sumsq/NR - (sum/NR)**2)}}' | awk -v chr="$chrom" '{{print"{wildcards.sample}\t"chr"\t"$0}}' >>  {input.bam_in}.dpth_by_chrom ; 
		done  """)

		#shell("""rm {input.bam_in}.dpth.tmp """)
		

		#https://www.biostars.org/p/5165/
		#save the depth file and offload the statistics to the bam_summarizer script?? 
		shell("python3 scripts/bam_summarizer.py -f {input.bam_in}.flagstat -i {input.bam_in}.idxstats -g {input.bam_in}.genomcov -d {input.bam_in}.dpthStats -o {output.report_out} -t {wildcards.sample}")


rule demand_BAM_analytics:
	input:
		bam_reports = lambda wildcards: expand("data/summaries/intermediate/BAMs/{aligner}/{sample}.vs_{ref_genome}.{aligner}.summary", sample=sampname_by_group[wildcards.group], ref_genome=wildcards.ref_genome, aligner=wildcards.aligner),
		dpth_reports = lambda wildcards: expand("data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.sort.bam.dpth_by_chrom", sample=sampname_by_group[wildcards.group], ref_genome=wildcards.ref_genome, aligner=wildcards.aligner)
	output:
#		full_report = "data/summaries/intermediate/BAMs/{group}.vs_{ref_genome}.{aligner}.summary"
		full_report = "data/summaries/intermediate/BAMs/{group, \w+}.vs_{ref_genome}.{aligner}.summary",
		all_dpth_by_chrom = "data/summaries/intermediate/BAMs/{group, \w+}.vs_{ref_genome}.{aligner}.dpth_by_chrom"
	params:
		runmem_gb=1,
		runtime="1:00",
		cores=1,
	message:
		"collecting all alignment metadata.... "
	shell:
		"cat {input.bam_reports} > {output.full_report}; cat {input.dpth_reports} > {output.all_dpth_by_chrom}"
#	cat test.samtools.idxstats | sed \$d | awk '{print $1, $3/$2}' > per_contig_coverage_depth
#	echo  $( cat test.samtools.idxstats |  sed \$d | cut -f 2 | paste -sd+ | bc) $(cat test.samtools.idxstats |  sed \$d | cut -f 3 | paste -sd+ | bc) | tr  " " "\t" | awk '{print "total\t"$1/$2}'

#
############################################################################  
#######		Call variants from mapped reads 	####
############################################################################  

#data/summaries/intermediate/BAMs/all.vs_dm6.bwaUniq.summary data/summaries/intermediate/BAMs/all.vs_droSim1.bwaUniq.summary data/summaries/intermediate/BAMs/all.vs_droSec1.bwaUniq.summary data/summaries/intermediate/BAMs/all.vs_dm6.bwa.summary data/summaries/intermediate/BAMs/all.vs_droSim1.bwa.summary data/summaries/intermediate/BAMs/all.vs_droSec1.bwa.summary 

rule joint_vcf_caller_parallel_stdFB:
	input:
		bams_in = lambda wildcards: expand("data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.sort.bam", sample=sampname_by_group[wildcards.group], ref_genome=wildcards.ref_genome, aligner=wildcards.aligner),
		windows_in = "utils/{ref_genome}_w100000_s100000.windows.bed"
	output:
		vcf_out = "data/intermediate/variants/stdFreeBayes/{group}.vs_{ref_genome}.{aligner}.vcf"
	params:
		freebayes="--standard-filters",
		runmem_gb=64,
		runtime="1-00:00:00",
		cores=18,
	message:
		"Jointly calling variants from all samples mapped to \ {wildcards.ref_genome} \ with \ {wildcards.aligner} \ "
	run:
		ref_genome_file=ref_genome_by_name[wildcards.ref_genome]['path']
		shell("""mkdir -p data/intermediate/variants/stdFreeBayes/ """)
		shell("""cat {input.windows_in}| awk '{{print$1":"$2"-"$3}}' > {input.windows_in}.rfmt""")
		shell("scripts/freebayes-parallel {input.windows_in}.rfmt {params.cores} {params.freebayes} -f {ref_genome_file} {input.bams_in} | vcftools --remove-indels --vcf - --recode --recode-INFO-all --stdout  > {output.vcf_out} ")
		#shell("~/modules/freebayes/scripts/freebayes-parallel {input.windows_in}.rfmt {params.cores}  --standard-filters -f {ref_genome_file} {input.bams_in} | vcftools --remove-indels --vcf - --recode --recode-INFO-all --stdout  > {output.vcf_out} ")
		#shell("freebayes {params.freebayes} -f {ref_genome_file} {input.bams_in} | vcftools --remove-indels --vcf - --recode --recode-INFO-all --stdout  > {output.vcf_out}")





rule cnv_bed_file_maker:
	input:
#		bams_in = lambda wildcards: expand("data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.sort.bam", sample=sampname_by_group[wildcards.group], ref_genome=wildcards.ref_genome, aligner=wildcards.aligner),
#		windows_in = "utils/{ref_genome}_w100000_s100000.windows.bed"
	output:
		cnv_out = "data/intermediate/variants/{group}.cnv_in.{ref_genome}.bed"
	params:
		hapcopynum=30,
		runmem_gb=1,
		runtime="00:10:00",
		cores=1,
	message:
		" "
	run:
		shell(""" rm -rf {output.cnv_out} """)
		fai=ref_genome_by_name[wildcards.ref_genome]['path']+".fai"
		for samp in sampname_by_group[wildcards.group]:
			if wildcards.ref_genome == "droSim1":
				shell(""" cat {fai} | grep "chr[XY]" | awk '{{print$1"\t1\t"$2"\t{samp}\t{params.hapcopynum}"}}' >> {output.cnv_out} || true """)
			elif wildcards.ref_genome == "prinDsim3":
				shell(""" cat {fai} | grep -w "NC_052525.2" | awk '{{print$1"\t1\t"$2"\t{samp}\t{params.hapcopynum}"}}' >> {output.cnv_out} || true """)



#cnv bed file format: reference sequence, start, end, sample name, copy number
#male flies, ie haploid in both sex chroms
# only works on well consolidated chrom


rule joint_vcf_caller_parallel_smrtFB:
	input:
		bams_in = lambda wildcards: expand("data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.sort.bam", sample=sampname_by_group[wildcards.group], ref_genome=wildcards.ref_genome, aligner=wildcards.aligner),
		windows_in = "utils/{ref_genome}_w100000_s100000.windows.bed",
		cnv_bed =  "data/intermediate/variants/{group}.cnv_in.{ref_genome}.bed", 
	output:
		vcf_out = "data/intermediate/variants/smrtFreeBayes/{group}.vs_{ref_genome}.{aligner}.vcf"
	params:
		freebayes=" --standard-filters --strict-vcf --use-best-n-alleles 8  --pooled-discrete --ploidy 60 ",# 30 flies per sample, diploid unless cnv_bed sez otherwise
#		freebayes=" --standard-filters --strict-vcf --use-best-n-alleles 8  --pooled-continuous --pooled-discrete --ploidy 60 ",# 30 flies per sample, diploid unless cnv_bed sez otherwise
#		freebayes=" --standard-filters --strict-vcf --use-best-n-alleles 8  --pooled-continuous --pooled-discrete --ploidy 60 ",# 30 flies per sample, diploid unless cnv_bed sez otherwise
		runmem_gb=64,
		runtime="1-00:00:00",
		cores=18,
	message:
		"Jointly calling variants from all samples mapped to \ {wildcards.ref_genome} \ with \ {wildcards.aligner} \ "
	run:
		ref_genome_file=ref_genome_by_name[wildcards.ref_genome]['path']


		shell("""mkdir -p data/intermediate/variants/smrtFreeBayes/ """)
		shell("""cat {input.windows_in}| awk '{{print$1":"$2"-"$3}}' > {input.windows_in}.rfmt""")
		shell("scripts/freebayes-parallel {input.windows_in}.rfmt {params.cores} --cnv-map {input.cnv_bed}  {params.freebayes} -f {ref_genome_file} {input.bams_in} | bcftools view  --types snps  > {output.vcf_out} ")




rule vcf_reporter:
	input:
		vcf_in = "data/intermediate/variants/{caller}/{prefix}.vs_{ref_genome}.{aligner}.vcf"
	output:
		report_out = "data/summaries/intermediate/VCFs/{ref_genome}/{caller}/{prefix}.vs_{ref_genome}.{aligner}.summary",
		frq_out = "data/intermediate/frequencies/{caller}/{prefix}.vs_{ref_genome}.{aligner}.frq"
	params:
		ploidy=30.,
		runmem_gb=8,
		runtime="4:00:00",
		cores=4,
#	message:
#		"Collecting metadata for the {wildcards.aligner} alignment of {wildcards.sample} to {wildcards.ref_genome}.... "
	run:
		shell("""
		mkdir -p data/intermediate/frequencies/{wildcards.caller}/ data/summaries/intermediate/VCFs/{wildcards.ref_genome}/{wildcards.caller}/
		""")

		shell("""
		cat {input.vcf_in}  | grep -v "#" | cut -f 1 | sort | uniq -c > {output.report_out}.snpsPerContig.tmp
		cat {output.report_out}.snpsPerContig.tmp | awk '{{sum+=$1}} END {{ print sum,"\ttotal"}}' | cat {output.report_out}.snpsPerContig.tmp - > {output.report_out}.snpsPerContig
		rm {output.report_out}.snpsPerContig.tmp
		ref_genome={wildcards.ref_genome}
		tail -n 1 {output.report_out}.snpsPerContig | awk '{{print "total_snp_count\t"$1}}' | sed -e 's/^/{wildcards.ref_genome}\t/g' > {output.report_out}
		""")
		
		if wildcards.caller in ["stdFreeBayes"]:
			shell("""
		vcftools  --vcf {input.vcf_in} --out {output.report_out} --freq 
		vcftools  --vcf {input.vcf_in} --out {output.report_out} --counts
		vcftools  --vcf {input.vcf_in} --out {output.report_out} --missing-indv
		vcftools  --vcf {input.vcf_in} --out {output.report_out} --missing-site
		vcftools  --vcf {input.vcf_in} --out {output.report_out} --singletons

		""")
				
		elif wildcards.caller in ["smrtFreeBayes"]:
			shell("""
			cat {input.vcf_in} | bcftools query -f '%CHROM\t%POS\t%AN\t%REF\t%ALT\t%N_PASS(GT!="mis")\t[%GT/]\n' > {output.frq_out}.tmp
			""")
			f_read = open(output.frq_out+".tmp", "r")
			lions = f_read.readlines()
			f_read.close()

			lions = [l.strip().split("\t") for l in lions]
		
			f_write = open(output.report_out+".frq.count", "w")
			f_write.write("CHROM\tPOS\tN_ALLELES\tN_CHR\t{ALLELE:FREQ}\n")

			for lyin in lions:
				gnu_lion = lyin[:2]
				gnu_lion.append(len(lyin[3]) + len(lyin[4].split(","))) # number alleles
#				num_chrom = float(lyin[5]) * 2 * params.ploidy # number of samples, with 30 diploid individuals per sample  
				num_chrom = lyin[-1].count("0") +lyin[-1].count("1")  
				gnu_lion.append(num_chrom) # number chromosomes

				gnu_lion.append("%s:%s" % (lyin[3], lyin[-1].count("0") )) # number chromosomes
				gnu_lion.append("%s:%s" % (lyin[4], lyin[-1].count("1") )) # number chromosomes
				f_write.write("\t".join([str(x) for x in gnu_lion])+"\n")
				
			f_write.close()
				
			f_write = open(output.report_out+".frq", "w")
			f_write.write("CHROM\tPOS\tN_ALLELES\tN_CHR\t{ALLELE:FREQ}\n")

			for lyin in lions:
				gnu_lion = lyin[:2]
				gnu_lion.append(len(lyin[3]) + len(lyin[4].split(","))) # number alleles
				#num_chrom = float(lyin[5]) * 2 * params.ploidy # number of samples, with 30 diploid individuals per sample 
				num_chrom = lyin[-1].count("0") +lyin[-1].count("1")  
 
				gnu_lion.append(num_chrom) # number chromosomes

				gnu_lion.append("%s:%s" % (lyin[3], lyin[-1].count("0")/num_chrom )) # number chromosomes
				gnu_lion.append("%s:%s" % (lyin[4], lyin[-1].count("1")/num_chrom )) # number chromosomes
				f_write.write("\t".join([str(x) for x in gnu_lion])+"\n")
			f_write.close()
			shell(""" rm {output.frq_out}.tmp""")

#

#		shell(""" rm -f {output.report_out}.imiss {output.report_out}.lmiss ; touch {output.report_out}.imiss {output.report_out}.lmiss ; """)

		shell("""
				cat {output.report_out}.frq | tail -n +2 | awk '{{print $1,$2,$2+1,$4,$5,$6}}' | tr " " "\t" > {output.frq_out}
		""")

	#cat  all_samples.vs_droSec1.bwaUniq.summary.frq.count| cut -f 3 | tail -n +2 | sort | uniq -c
	#####	bi, tri, and quadralelic counts ^^ 
	#replace some of this with vcftools::vcf-stats ?



rule summon_VCF_analytics_base:
	input:
		bam_reports = lambda wildcards: expand("data/summaries/intermediate/VCFs/{ref_genome}/{caller}/{prefix}.vs_{ref_genome}.{aligner}.summary", prefix=wildcards.prefix, ref_genome=["droSim1", "ncbiMau"], aligner="bwaUniq", caller = ["stdFreeBayes","smrtFreeBayes"])#,"ncbiMau"], aligner="bwaUniq")
	output:
		full_report = "data/summaries/intermediate/VCFs/{prefix}.calledVariants.{aligner}.summary"
	params:
		runmem_gb=1,
		runtime="1:00",
		cores=1,
	message:
		"collecting all alignment metadata.... "
	run:

		shell(""" rm -f {output.full_report} """)
		for caller in ["stdFreeBayes","smrtFreeBayes",]:
			for ref_genome in ["droSim1", "ncbiMau"]:
				shell(""" cat data/summaries/intermediate/VCFs/{ref_genome}/{caller}/{wildcards.prefix}.vs_{ref_genome}.{wildcards.aligner}.summary | awk '{{print"{wildcards.prefix}\t{caller}\t"$0}}' >> {output.full_report} """)



rule subset_VCF_to_subgroup:
	input:
		vcf_in = "data/intermediate/variants/{prefix}/{group,[^\/]+}.vs_{ref_genome}.{aligner}.vcf"
	output:
		vcf_out = "data/intermediate/variants/{prefix}/{group,[^\/]+}.subset_{subgroup}.vs_{ref_genome}.{aligner}.vcf"
	params:
		runmem_gb=8,
		runtime = "1:00:00",
		cores=2,
	message:
		"Subsetting the variant file \ {input.vcf_in} \ to the individuals in the subgroup \ {wildcards.subgroup} \ .... "
	run:

		member_list = "%s,"*len(sampname_by_group[wildcards.subgroup]) % tuple(sampname_by_group[wildcards.subgroup])
		
		# filter_string = " --min-alleles 2 --max-alleles 2  --max-missing-count 0" # --non-ref-ac-any 1" # only biallelic sites, no missing genotypes, invariant sites allowed b/c they might vary relative to a different subgroup
		# shell("vcf-subset {input.vcf_in} -u -c {member_list} | vcftools {filter_string} --vcf - --recode --stdout > {output.vcf_out}")

		filter_string = " --min-alleles 2 --max-alleles 2 --types snps --exclude 'F_MISSING>0' "
		shell("vcf-subset {input.vcf_in} -u -c {member_list} | bcftools +fill-tags -  -- -t AF,AC,F_MISSING,NS,AN | bcftools view {filter_string}  > {output.vcf_out}")


rule window_maker:
	output:
		windowed='utils/{ref_genome}_w{window_size}_s{slide_rate}.windows.bed'
	params:
		runmem_gb=8,
		runtime="5:00",
		cores=1,
	run:
		fai_path = ref_genome_by_name[wildcards.ref_genome]['fai'],
		shell("mkdir -p utils")
		shell(
			'bedtools makewindows -w {wildcards.window_size} -s {wildcards.slide_rate} -g {fai_path} -i winnum | bedtools sort -i - > {output.windowed}'
		)


############################################################################  
#######		windowed frequency comparison between groups 	################
############################################################################  



rule calc_frq_shift:
	input:
		par1_frq = "data/intermediate/frequencies/{prefix}.subset_{grup_par1}.vs_{ref_genome}.{aligner}.frq",
		par2_frq = "data/intermediate/frequencies/{prefix}.subset_{grup_par2}.vs_{ref_genome}.{aligner}.frq",
		off_frq = "data/intermediate/frequencies/{prefix}.subset_{grup_off}.vs_{ref_genome}.{aligner}.frq",
	output:
		frqShft_out = "data/intermediate/freq_shift/{prefix}.{grup_off}_with_{grup_par1}_and_{grup_par2}.vs_{ref_genome}.{aligner}.frqShift"
	params:
		runmem_gb=16,
		runtime="1:00:00",
		cores=2,
	shell:
		"""
		mkdir -p data/intermediate/freq_shift/
		bedtools intersect -wa -wb -a {input.par1_frq} -b  {input.par2_frq} | bedtools intersect -wa -wb -a - -b  {input.off_frq} | cut -f 1,2,4-6,10,12,16,18 | tr ":" "\t" | awk '{{print $1,$2,$2+1,"0","0","+",$4,$6,$3,$7,$8,$10,$11,$13}}' | tr " " "\t" > {output.frqShft_out}.pre
		Rscript scripts/freqShifter.R {output.frqShft_out}.pre {output.frqShft_out}
		rm {output.frqShft_out}.pre
		"""

#	no need for biallelic check - that's done in the subsetting
#	add a check to make sure that it's the same allele in each case, write down the cases which aren't????

rule window_frq_shift:
	input:
		frqShft_in = "data/intermediate/freq_shift/{frqshft_prefix}.vs_{ref_genome}.{aligner}.frqShift",
		windows_in = "utils/{ref_genome}_w{window_size}_s{slide_rate}.windows.bed"
	output:
		windowed_out = "data/ultimate/freq_shift/{frqshft_prefix}.vs_{ref_genome}.{aligner}.windowed_w{window_size}_s{slide_rate}.frqShift.bed"
	params:
		runmem_gb=16,
		runtime="1:00:00",
		cores=4,
	shell:
		"""
		mkdir -p data/ultimate/freq_shift/
		bedtools map -c 7,8,8 -o sum,sum,count -null NA -a {input.windows_in} -b <( tail -n +2  {input.frqShft_in} | cut -f  1-3,15,16 | nl | tr -d " " | awk '{{if( $5!="NA" && $6!="NA")print $2,$3,$4,$1,"0",".",$5,$6}}' | tr " " "\t"| bedtools sort -i - ) > {output.windowed_out}
  		"""



############################################################################  
#######		other VCF statistics 	####
############################################################################  

rule population_VCF_het:
	input: 
		varz = "data/intermediate/variants/{prefix}.vs_{ref_genome}.{aligner}.vcf", 
		windows_in = "utils/{ref_genome}_w{window_size}_s{slide_rate}.windows.bed",
	output:
		het_out = "data/intermediate/population_genetics/heterozygosity/{prefix}.vs_{ref_genome}.{aligner}.het.w{window_size}_s{slide_rate}.bg",
	params:
		runmem_gb=8,
		runtime="12:00:00",
		cores=8,
		win_size = 10000,
	run:

		shell(""" mkdir -p data/intermediate/population_genetics/heterozygosity/; rm -rf {output.het_out}; bgzip --stdout {input.varz} > {input.varz}.bgz; tabix {input.varz}.bgz ;  """)
		shell(""" 
while read -r line; do 
	echo $line;
	echo $line | tr " " "\t" > {output.het_out}.tmp.bed ; 
	bcftools view -R {output.het_out}.tmp.bed {input.varz}.bgz | vcftools --vcf - --het --stdout | tail -n +2 | awk -v s="$line" '{{print s"\t0\t*\t"$0}}' | tr " " "\t" >> {output.het_out}
done < {input.windows_in}

 """)
		shell(""" rm -rf {input.varz}.bgz* ;  """)




rule genelist2genebed:
	input:
		gene_list='utils/genelists/{ref_gen}/{genelist}.list',
	output:
		#windowed_out = "data/ultimate/freq_shift/{var_caller}/{frqshft_prefix}.listWindowed_l{slopsize}.frqShift.bed"
		gene_bed = "utils/genelists/{ref_gen}/{genelist}.listWindowed_l{slopsize,[0-9]+}.bed"
	params:
		runmem_gb=8,
		runtime="1:00:00",
		cores=8,
	run:
		egg = annotation_by_name["NCBIsim103"]["gtf_path"]
		fai = ref_genome_by_name[wildcards.ref_gen]["path"]+".fai"
		shell(""" grep -wFf <(  cat {input.gene_list} | cut -f 1 ) {egg} | awk '{{if($3=="gene")print;}}' | cut -f 1,4,5,9 | cut -f 1,2 -d '"' | sed -e 's/gene_id "//g' | bedtools slop -i - -g {fai} -b {wildcards.slopsize} > {output.gene_bed} """ )


rule shuffle_genebed:
	input:
		gene_bed = "utils/genelists/{ref_gen}/{genelist}.listWindowed_l{slopsize,[0-9]+}.bed"
	output:
		#windowed_out = "data/ultimate/freq_shift/{var_caller}/{frqshft_prefix}.listWindowed_l{slopsize}.frqShift.bed"
		shuff_bed = "utils/genelists/{ref_gen}/{genelist}.listWindowed_l{slopsize,[0-9]+}_f{replicate}.bed"
	params:
		runmem_gb=8,
		runtime="1:00:00",
		cores=8,
	run:
#		egg = annotation_by_name["NCBIsim103"]["gtf_path"]
		fai = ref_genome_by_name[wildcards.ref_gen]["path"]+".fai"
		shell(""" bedtools shuffle -chrom -noOverlapping -i {input.gene_bed} -g {fai} > {output.shuff_bed}""" )

rule resample_genebed:
	input:
		gene_bed = "utils/genelists/{ref_gen}/{genelist}.listWindowed_l{slopsize,[0-9]+}.bed"
	output:
		#windowed_out = "data/ultimate/freq_shift/{var_caller}/{frqshft_prefix}.listWindowed_l{slopsize}.frqShift.bed"
		resamp_bed = "utils/genelists/{ref_gen}/{genelist}.listWindowed_l{slopsize,[0-9]+}_m{replicate}.bed"
	params:
		runmem_gb=8,
		runtime="1:00:00",
		cores=8,
	run:
		shell(""" rm -f {output.resamp_bed} """)
		egg = annotation_by_name["NCBIsim103"]["gtf_path"]
		fai = ref_genome_by_name[wildcards.ref_gen]["path"]+".fai"
#		pull_string = """awk '{{if(\$3==\"gene\")print;}}'"""
#		shell(""" cat {input.gene_bed} | cut -f 1 | sort | uniq -c | awk -var awkward="{pull_string}" '{{ print " cat {egg} | "awkward" | sort -R | grep -w "$2" | head -n "$1}}' | sh  | cut -f 1,4,5,9 | cut -f 1,2 -d '"' | sed -e 's/gene_id "//g' | bedtools slop -i - -g {fai} -b {wildcards.slopsize} > {output.resamp_bed} """ )
		shell(""" cat {input.gene_bed} | cut -f 1 | sort | uniq -c | awk '{{print "cat {egg} | awk ~{{if($1 == \\""$2"\\" && $3 == \\"gene\\")print;}}~ |sort -R |  head -n "$1" | gtf2bed | cut -f 1-6 | bedtools  slop -i - -g {fai} -b {wildcards.slopsize} | cut -f 1-4 >> {output.resamp_bed} "}}' | tr "~" "'" | sh """ )



rule genelist_frq_shift:
	input:
#		shared_snps='data/intermediate/shared_snps/PsiSeq/{ref_genome}/{aligner}/{sample}.SNPs_shared_with.{eff_naught}.vs_{ref_genome}.{aligner}.bed'
#		shared_snps='data/intermediate/shared_snps/PsiSeq2/{ref_genome}/{aligner}/{sample}_in_{eff_naught}.vs_{ref_genome}.{aligner}.sharedSNPs.bed'
		frqShft_in = "data/intermediate/freq_shift/{frqshft_prefix}.vs_{ref_genome}.{aligner}.frqShift",
		windows_in = "utils/genelists/{ref_genome}/{genelist}.listWindowed_{list_suffix}.bed"
	output:
		windowed_out = "data/ultimate/freq_shift/{frqshft_prefix}.vs_{ref_genome}.{aligner}.{genelist}_listWindowed_{list_suffix}.frqShift.bed"
	params:
		runmem_gb=32,
		runtime="1:00:00",
		cores=4,
	shell:
		"""
		mkdir -p data/ultimate/freq_shift/
		bedtools map -c 7,8,8 -o sum,sum,count -null NA -a <( cat {input.windows_in} | bedtools sort -i -)  -b <( tail -n +2  {input.frqShft_in} | cut -f  1-3,15,16 | nl | tr -d " " | awk '{{if( $5!="NA" && $6!="NA")print $2,$3,$4,$1,"0",".",$5,$6}}' | tr " " "\t"| bedtools sort -i - ) > {output.windowed_out}
  		"""







rule write_report:
	input:
		reference_summary = ["data/summaries/reference_genomes/reference_genomes.summary", "data/summaries/reference_annotations/reference_annotations.summary"],
		sequenced_reads_summary=["data/summaries/intermediate/FASTP/all.sequenced_reads.dat"],
		alignment_summaries = expand("data/summaries/intermediate/BAMs/all.vs_{ref_gen}.{aligner}.summary", ref_genome=['droSim1', 'ncbiMau','prinDsim3'], aligner=['bwa','bwaUniq']),

		PsiSeq_legacy = expand("data/ultimate/shared_SNPs/PsiSeq{version}/droSim1/bwaUniq/{sample_1}.SNPs_shared_with.{sample_2}.vs_droSim1.bwaUniq.genomeWindowed_w100000_s50000.bed", sample_1 = ["BCM10F", "BCM10NE", "BCS10F", "BCS10NE", "mauGFP", "simGFP"], sample_2 = ["BCM10F", "BCM10NE", "BCS10F", "BCS10NE", "mauGFP", "simGFP"], version = ["","2", "2_relaxed"]),

		std_freebayes_bin = expand("data/ultimate/freq_shift/stdFreeBayes/all.simBackcrossMutant_with_simulans_and_mauritiana.vs_droSim1.bwaUniq.snpBinned_b120_s60.frqShift.bed", sample = ["simBackcrossMutant","simBackcrossNormal","mauritiana"], bins = ["b120_s60", "b12500_s6250", "b1250_s625"]),
		std_freebayes_winSize = expand("data/ultimate/freq_shift/stdFreeBayes/all.simBackcrossNormal_with_simulans_and_mauritiana.vs_droSim1.bwaUniq.windowed_{wins}.frqShift.bed", sample = ["simBackcrossMutant","simBackcrossNormal","mauritiana"], wins = ["w10000_s5000","w1000000_s500000"])
		std_freebayes = expand("data/ultimate/freq_shift/stdFreeBayes/all.{sample}_with_simulans_and_mauritiana.vs_droSim1.bwaUniq.windowed_w100000_s50000.frqShift.bed", sample = ["mauBackcrossMutant","mauBackcrossNormal","mauritiana","mauritianaBackcross","mutantSperm","normalSperm","simBackcrossMutant","simBackcrossNormal","simulans","simulansBackcross"])
		smrt_freebayes = expand("data/ultimate/freq_shift/smrtFreeBayes/all.{sample}_with_simulans_and_mauritiana.vs_prinDsim3.bwaUniq.windowed_w100000_s50000.frqShift.bed", sample = ["mauBackcrossMutant","mauBackcrossNormal","mauritiana","mauritianaBackcross","mutantSperm","normalSperm","simBackcrossMutant","simBackcrossNormal","simulans","simulansBackcross"], ref_genome = ["prinDsim3", "droSim1"])

		popgen = ["data/intermediate/population_genetics/heterozygosity/stdFreeBayes/all.vs_droSim1.bwaUniq.het.w100000_s50000.bg"]

	output:
		pdf_out="results/Moehring_PopPsiSeq.pdf"
	params:
		runmem_gb=8,
		runtime="1:00:00",
		cores=2,
	message:
		"writing up the results.... "
	run:
		pandoc_path="/nas/longleaf/apps/rstudio/2021.09.2-382/bin/pandoc"
		pwd = subprocess.check_output("pwd",shell=True).decode().rstrip()+"/"
		shell("""mkdir -p results/figures/supp/ results/tables/supp/""")
		shell(""" R -e "setwd('{pwd}');Sys.setenv(RSTUDIO_PANDOC='{pandoc_path}')" -e  "peaDubDee='{pwd}'; rmarkdown::render('scripts/Moehring_PopPsiSeq.Rmd',output_file='{pwd}{output.pdf_out}')"  """)
#               shell(""" tar cf results.tar results/ """)




















########################	LEGACY RULES	########################







rule mpiler:
	input:
		sorted_bam = "data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.sort.bam",
	output:
		mpile = "data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.mpileup",
	params:
		runmem_gb=8,
		runtime="3:00:00",
		cores=1,
	run:
		ref_genome = ref_genome_by_name[wildcards.ref_genome]['path']		
		shell(
		"samtools mpileup -Bf {ref_genome} {input.sorted_bam} > {output.mpile}"
		)


rule window_sharedSnps:
	input:
#		shared_snps='data/intermediate/shared_snps/PsiSeq/{ref_genome}/{aligner}/{sample}.SNPs_shared_with.{eff_naught}.vs_{ref_genome}.{aligner}.bed'
#		shared_snps='data/intermediate/shared_snps/PsiSeq2/{ref_genome}/{aligner}/{sample}_in_{eff_naught}.vs_{ref_genome}.{aligner}.sharedSNPs.bed'
		shared_snps='data/intermediate/shared_snps/PsiSeq{version}/{ref_genome}/{aligner}/{sharedSnp_prefix}.bed',
		windows_in = "utils/{ref_genome}_w{window_size}_s{slide_rate}.windows.bed"
	output:
		windowed_out = "data/ultimate/shared_SNPs/PsiSeq{version,.*}/{ref_genome}/{aligner}/{sharedSnp_prefix}.genomeWindowed_w{window_size}_s{slide_rate}.bed"
	params:
		runmem_gb=32,
		runtime="1:00:00",
		cores=4,
	shell:
		"""
		mkdir -p data/ultimate/shared_SNPs/PsiSeq{wildcards.version}/{wildcards.ref_genome}/{wildcards.aligner}/ ;
		bedtools map -c 4,4 -o sum,count -null NA -a {input.windows_in} -b <(  bedtools sort -i {input.shared_snps} ) > {output.windowed_out} ;
  		"""
#		bedtools map -c 4,4 -o sum,count -null NA -a {input.windows_in} -b <(  sort -k 1,1 -k2,2n {input.shared_snps} ) > {output.windowed_out} ;




rule bin_sharedSNPs:
	input:
		shared_snps='data/intermediate/shared_snps/PsiSeq{version}/{ref_genome}/{aligner}/{sharedSnp_prefix}.bed',
	output:
		windowed_out = "data/ultimate/shared_SNPs/PsiSeq{version,.*}/{ref_genome}/{aligner}/{sharedSnp_prefix}.snpBinned_b{bin_size}_s{slide_rate}.bed"
	params:
		runmem_gb=8,
		runtime="1:00:00",
		cores=8,
	run:
		shell("python3 scripts/bin_by_SNPs.py -i {input.shared_snps} -o {output.windowed_out}.tmp -b {wildcards.bin_size} -s {wildcards.slide_rate} -m sum,count -c 4,4" )
		shell("paste <( cut -f 1-3 {output.windowed_out}.tmp ) <( cut -f 4- {output.windowed_out}.tmp | nl -n rz ) > {output.windowed_out}")
		shell("rm {output.windowed_out}.tmp " )


rule bin_frqShft:
	input:
		shared_snps='data/intermediate/freq_shift/{var_caller}/{frqshft_prefix}.frqShift',
	output:
		windowed_out = "data/ultimate/freq_shift/{var_caller}/{frqshft_prefix}.snpBinned_b{bin_size}_s{slide_rate}.frqShift.bed"
	params:
		runmem_gb=8,
		runtime="1:00:00",
		cores=8,
	run:
		shell("python3 scripts/bin_by_SNPs.py -i {input.shared_snps} -o {output.windowed_out}.tmp -b {wildcards.bin_size} -s {wildcards.slide_rate}  -c 15,16,16 -m 'sum,sum,count' --header_skip 1 " )
		shell("paste <( cut -f 1-3 {output.windowed_out}.tmp ) <( cut -f 4- {output.windowed_out}.tmp | nl -n rz ) > {output.windowed_out}")
		shell("rm {output.windowed_out}.tmp " )





####				PsiSeq			##########

rule og_framenter:
	output:
		sim_seq='data/simulated/sequence/single_end/erics_fragmenter/{ref_genome}.L{read_len}.C{coverage}.E0.{error_freq}.fastq'
	params:
		runmem_gb=8,
		runtime="3:00:00",
		cores=1,
	run:
		#lookup ref gen file from config
		#
#		perl fragmenter.pl reference.fa output.fa read-length coverage artificial-error-frequency
		err = float("0." + wildcards.error_freq)
		genome = ref_genome_by_name[wildcards.ref_genome]["path"]

		shell(""" perl scripts/legacy/PsiSeq/fragmenter.pl {genome} data/simulated/sequence/single_end/erics_fragmenter/{wildcards.ref_genome}.L{wildcards.read_len}.C{wildcards.coverage}.E0.{wildcards.error_freq}.fasta {wildcards.read_len} {wildcards.coverage} {err} """)
		#https://bioinformatics.stackexchange.com/a/11213
		shell(""" cat data/simulated/sequence/single_end/erics_fragmenter/{wildcards.ref_genome}.L{wildcards.read_len}.C{wildcards.coverage}.E0.{wildcards.error_freq}.fasta | paste - - | perl -ne 'chomp; s/^>/@/; @v = split /\t/; printf("%s\n%s\n+\n%s\n", $v[0], $v[1], "B"x length($v[1]))' > {output.sim_seq} """)


rule PsiSeq1:
	input:
		offspring_mpile='data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.mpileup',
		otherparent_mpile="data/intermediate/mapped_reads/{aligner}/{eff_naught}.vs_{ref_genome}.{aligner}.mpileup",
	output:
		shared_snps='data/intermediate/shared_snps/PsiSeq/{ref_genome}/{aligner}/{sample}.SNPs_shared_with.{eff_naught}.vs_{ref_genome}.{aligner}.bed'
	params:
		runmem_gb=8,
		runtime="24:00:00",
		cores=1,
	run:
		shell(
		"""
		perl scripts/legacy/PsiSeq/shared_snps_v3.1.pl {input.offspring_mpile} {input.otherparent_mpile} {output.shared_snps}.pre;
		cat {output.shared_snps}.pre | awk '{{print$1"\t"$2"\t"$2"\t"$3}}' | bedtools sort > {output.shared_snps}
		rm {output.shared_snps}.pre ;
		"""
		)





####				PsiSeq2			##########

rule shared_snipper:
	input:
		offspring_mpile='data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.mpileup',
		otherparent_mpile="data/intermediate/mapped_reads/{aligner}/{eff_naught}.vs_{ref_genome}.{aligner}.mpileup",
	output:
#		shared_snps='data/intermediate/shared_snps/PsiSeq2/{ref_genome}/{aligner}/{sample}_in_{eff_naught}.vs_{ref_genome}.{aligner}.sharedSNPs.bed'
		shared_snps='data/intermediate/shared_snps/PsiSeq2/{ref_genome}/{aligner}/{sample}.SNPs_shared_with.{eff_naught}.vs_{ref_genome}.{aligner}.bed'
#		shared_snps='variant_comparisons/{sample}_and_{compare}_vs_{parent}.{aligner}.sharedSnps.out'
	params:
		minCov=3,
		runmem_gb=64,
		minFrac=0.9,
		cores=8,
		runtime="6:00:00"
	run:
		uniq1 = subprocess.check_output(""" echo $(date +%N)*$(date +%N) | bc | md5sum | cut -f 1 -d " "  """  ,shell=True).decode().rstrip()[-5:].upper()		
		uniq2 = subprocess.check_output(""" echo $(date +%N)*$(date +%N) | bc | md5sum | cut -f 1 -d " "  """  ,shell=True).decode().rstrip()[-5:].upper()		
		shell(""" mkdir -p data/intermediate/shared_snps/PsiSeq2/{wildcards.ref_genome}/{wildcards.aligner}/  """)
#		suffix = ''.join(wildcards.sample(ascii_uppercase + digits, k=10))
		shell(""" cat {input.offspring_mpile} | awk '{{if($4 >= {params.minCov})print;}}' > {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniq1} """)
		shell(""" cat {input.otherparent_mpile}| awk '{{if($4 >= {params.minCov})print;}}' > {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniq2} """)
		fai = ref_genome_by_name[wildcards.ref_genome]["fai"]
		shell("python3 scripts/legacy/PsiSeq2/shared_snps.v4.py -vvvvv -c {params.minCov} -f {params.minFrac} -F {fai} {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniq1} {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniq2} {output.shared_snps}.tmp ")
		shell(" cat {output.shared_snps}.tmp | bedtools sort > {output.shared_snps} ")
		shell("rm {output.shared_snps}.tmp ") 
		#shell(" echo {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniquifier} {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniquifier} ")
		shell(" head {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniq1} {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniq2} ")
		#shell(" mv {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniquifier} {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniquifier} ")
		shell(" rm {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniq1}  ")
		shell(" rm {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniq2}  ")



rule PsiSeq2_relaxed:
	input:
		offspring_mpile='data/intermediate/mapped_reads/{aligner}/{sample}.vs_{ref_genome}.{aligner}.mpileup',
		otherparent_mpile="data/intermediate/mapped_reads/{aligner}/{eff_naught}.vs_{ref_genome}.{aligner}.mpileup",
	output:
#		shared_snps='data/intermediate/shared_snps/PsiSeq2/{ref_genome}/{aligner}/{sample}_in_{eff_naught}.vs_{ref_genome}.{aligner}.sharedSNPs.bed'
		shared_snps='data/intermediate/shared_snps/PsiSeq2_relaxed/{ref_genome}/{aligner}/{sample}.SNPs_shared_with.{eff_naught}.vs_{ref_genome}.{aligner}.bed'
#		shared_snps='variant_comparisons/{sample}_and_{compare}_vs_{parent}.{aligner}.sharedSnps.out'
	params:
		minCov=3,
		runmem_gb=64,
		minFrac=0.5,
		cores=8,
		runtime="6:00:00"
	run:
		uniq1 = subprocess.check_output(""" echo $(date +%N)*$(date +%N) | bc | md5sum | cut -f 1 -d " "  """  ,shell=True).decode().rstrip()[-5:].upper()		
		uniq2 = subprocess.check_output(""" echo $(date +%N)*$(date +%N) | bc | md5sum | cut -f 1 -d " "  """  ,shell=True).decode().rstrip()[-5:].upper()		
		shell(""" mkdir -p data/intermediate/shared_snps/PsiSeq2/{wildcards.ref_genome}/{wildcards.aligner}/  """)
		shell(""" cat {input.offspring_mpile} | awk '{{if($4 >= {params.minCov})print;}}' > {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniq1} """)
		shell(""" cat {input.otherparent_mpile}| awk '{{if($4 >= {params.minCov})print;}}' > {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniq2} """)
		fai = ref_genome_by_name[wildcards.ref_genome]["fai"]
		shell("python3 scripts/legacy/PsiSeq2/shared_snps.v4.py -vvvvv -c {params.minCov} -f {params.minFrac} -F {fai} {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniq1} {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniq2} {output.shared_snps}.tmp ")
		shell(" cat {output.shared_snps}.tmp | bedtools sort > {output.shared_snps} ")
		shell("rm {output.shared_snps}.tmp ") 
		#shell(" echo {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniquifier} {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniquifier} ")
		shell(" head {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniq1} {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniq2} ")
		#shell(" mv {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniquifier} {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniquifier} ")
		shell(" rm {input.offspring_mpile}.filtCov.{wildcards.eff_naught}.{uniq1}  ")
		shell(" rm {input.otherparent_mpile}.filtCov.{wildcards.sample}.{uniq2}  ")




rule lifter:
	input:
#		unlifted='variant_comparisons/{sample}_and_{compare}_vs_{parent}.{aligner}.sharedSnps.bed'
		unlifted='data/intermediate/shared_snps/PsiSeq{version}/{ref_genome}/{aligner}/{sample}.SNPs_shared_with.{eff_naught}.vs_{ref_genome}.{aligner}.bed'
	output:
		lifted='data/intermediate/shared_snps/PsiSeq{version,.*}/{lift_genome}/{aligner}/{sample}.SNPs_shared_with.{eff_naught}.vs_{ref_genome}.{aligner}.lifted_to_{lift_genome}.bed',
		too_heavy='data/intermediate/shared_snps/PsiSeq{version,.*}/{lift_genome}/{aligner}/{sample}.SNPs_shared_with.{eff_naught}.vs_{ref_genome}.{aligner}.2Heavy2Lift_to_{lift_genome}'
	params:
		runmem_gb=32,
		runtime="12:00:00",
		cores=1
	run:
		chain = chain_dict_by_destination[wildcards.lift_genome][wildcards.ref_genome]
		shell("mkdir -p data/intermediate/shared_snps/PsiSeq{wildcards.version}/{wildcards.lift_genome}/{wildcards.aligner}/")
		shell(
			'/nas/longleaf/home/csoeder/modules/UCSC_utils/liftOver {input.unlifted} {chain} {output.lifted}.tmp {output.too_heavy}'
		)
		shell(
			'bedtools sort -i {output.lifted}.tmp > {output.lifted}'
		)
		shell(
			'rm {output.lifted}.tmp'
		)

# snekjob data/intermediate/shared_snps/PsiSeq/dm6/bwaUniq/Earley2011.SNPs_shared_with.fragSimulated_dSim1.vs_droSec1.bwaUniq.lifted_to_dm6.bed data/intermediate/shared_snps/PsiSeq/dm6/bwaUniq/Earley2011.SNPs_shared_with.fragSimulated_dSim1.vs_droSim1.bwaUniq.lifted_to_dm6.bed --rerun-triggers mtime &

####################################################################


# data/ultimate/freq_shift/all.mauritianaBackcross_with_simulans_and_mauritiana.vs_droSim1.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.mauritianaBackcross_with_simulans_and_mauritiana.vs_ncbiMau.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.mauritiana_with_simulans_and_mauritiana.vs_droSim1.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.mauritiana_with_simulans_and_mauritiana.vs_ncbiMau.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.mutantSperm_with_simulans_and_mauritiana.vs_droSim1.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.mutantSperm_with_simulans_and_mauritiana.vs_ncbiMau.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.normalSperm_with_simulans_and_mauritiana.vs_droSim1.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.normalSperm_with_simulans_and_mauritiana.vs_ncbiMau.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.simulansBackcross_with_simulans_and_mauritiana.vs_droSim1.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.simulansBackcross_with_simulans_and_mauritiana.vs_ncbiMau.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.simulans_with_simulans_and_mauritiana.vs_droSim1.bwaUniq.windowed_w100000_s50000.frqShift.bed
# data/ultimate/freq_shift/all.simulans_with_simulans_and_mauritiana.vs_ncbiMau.bwaUniq.windowed_w100000_s50000.frqShift.bed




["data/ultimate/shared_SNPs/PsiSeq"+v+"/"+refgen+"/"+aln+"/"+samp+".SNPs_shared_with."+f0+".vs_"+refgen+"."+aln+".genomeWindowed_w100000_s50000.bed" for v in ["","2"] for refgen in ["droSim1","ncbiMau"] for aln in ["bwaUniq"] for f0 in ["simGFP","mauGFP"] for samp in ["BCM10F","BCM10NE","BCS10F","BCS10NE","mauGFP","simGFP"] ] 



